{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dcca71b-b72f-4699-b956-1e25929aa311",
   "metadata": {},
   "source": [
    "# Optimizer Step: Integrate Localization and Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e0feb0-c6bc-4079-9946-32bf0e96f301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import transformer_lens\n",
    "import torch, gc, itertools, functools, tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import modelHandlers, dataLoaders, gradient, evaluation, localizing, intervening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67623921-6d0d-498e-a112-4a2ccccad640",
   "metadata": {},
   "source": [
    "## Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7b84de32-0f84-4ac8-b393-e45add133d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-medium into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = modelHandlers.load_model(model_type=\"gpt2-medium\", DEVICE=\"cpu\", lr=0.0, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee438f85-dd13-4d26-b9ac-9078b111f17d",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0b51b9c7-afac-4957-8db9-44e200599e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl, test_dl = dataLoaders.batched_pile(mem_batch=1, non_mem_batch=5, test_frac=0.0, load_data=\"acc/gpt2-medium\", set_twice=None)\n",
    "#train_dl = dataLoaders.batched_pop_seqs(model, mem_batch=1, non_mem_batch=50)\n",
    "c_toks_NI, k_toks_NI = next(iter(train_dl))\n",
    "c_toks_NI, k_toks_NI = c_toks_NI.squeeze(0), k_toks_NI.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c49a654f-75c2-4497-bae0-93efcb41851f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fc48c8774f4526b56d2055dd4d26aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634ed1ef0c3645c2a48bc779e1240710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_orig_pred_NI = model.generate(input=c_toks_NI[:,:50], max_new_tokens=50, do_sample=False)\n",
    "k_orig_pred_NI = model.generate(input=k_toks_NI[:,:50], max_new_tokens=50, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4295a0e6-f7a1-4f02-9f5d-be39b813f151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_eval(model,c_NI:torch.LongTensor=None,c_orig_pred_NI:torch.LongTensor=None,k_NI:torch.LongTensor=None,k_orig_pred_NI:torch.LongTensor=None,I_range:list=[50,100], print_pred:bool=True):\n",
    "    \"\"\"\n",
    "    evaluate the language model on individual batches of c_toks_NI and k_toks_NI\n",
    "    \"\"\"\n",
    "    ## change set\n",
    "    (c_mean_nll, c_minK_nll), (_, _) = evaluation.evaluate_nll_greedy(model, c_NI, batch_size=50)\n",
    "    c_NI_pred = model.generate(input=c_NI[:,:50], max_new_tokens=50, do_sample=False)\n",
    "    c_em_N = evaluation.compute_exact_match(c_NI_pred[...,-(I_range[1]-I_range[0]):], c_orig_pred_NI[:,-(I_range[1]-I_range[0]):], until_wrong=False)\n",
    "    \n",
    "    ## keep set\n",
    "    (k_mean_nll, k_minK_nll), (_, _) = evaluation.evaluate_nll_greedy(model, k_NI, batch_size=50)\n",
    "    k_NI_pred = model.generate(input=k_NI[:,:50], max_new_tokens=I_range[1]-I_range[0], do_sample=False)\n",
    "    k_em_N = evaluation.compute_exact_match(k_NI_pred[...,-(I_range[1]-I_range[0]):], k_orig_pred_NI[:,-(I_range[1]-I_range[0]):], until_wrong=False)\n",
    "\n",
    "    ## process change and keep set\n",
    "    c_mean_nll, k_mean_nll = round(c_mean_nll[:,I_range[0]:I_range[1]].mean().detach().item(),4), round(k_mean_nll[:,I_range[0]:I_range[1]].mean().detach().item(),4)\n",
    "    c_em_N, k_em_N = c_em_N.mean().item(), k_em_N.mean().item()\n",
    "        \n",
    "    print(f\"---Greedy EM--- change set: {c_em_N}, keep set: {k_em_N}  [mean over {k_NI.shape[0]} seqs]\")\n",
    "    print(f\"---Mean NLL--- change set: {c_mean_nll}, keep set: {k_mean_nll}\")\n",
    "    \n",
    "    if print_pred:\n",
    "        print(f\"c_NI_pred: {model.to_string(c_NI_pred)}\")\n",
    "        print(f\"k_NI_pred: {model.to_string(k_NI_pred)}\")\n",
    "    #return (c_em_N, k_em_N), (c_mean_nll, k_mean_nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "215fc4c5-a787-45d9-8acb-7aaa58cb0f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4bc82841004ab593269aaaa50f275c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7743c2b7f84492780c30786e48cecd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Greedy EM--- change set: 50.0, keep set: 50.0  [mean over 5 seqs]\n",
      "---Mean NLL--- change set: 0.987, keep set: 5.2917\n",
      "c_NI_pred: [' is currently unavailable. Please, try again later. View profileView wishlistStart conversationInvite to friendsInvite to friendsAccept invitationAccept invitationPending invitation...User since {{ user.formattedDateUserJoined }} Friends since {{ user.formattedDateUserFriended }} {{ user.formattedDateUserExists }} {{ user.formattedDateUserIsOffline }} {{ user.formattedDateUserIsJoined }} {{ user.formattedDateUserIsFriends }} {{ user.form']\n",
      "k_NI_pred: [' Islam. They either rape them or sell them on for £10 or so to new masters. The girls are the victims of slavery, child abuse and forced marriage. Their captors are by extension slavers and rapists.\\n\\nAs you can see, the Islamic State is not a religion. It is a criminal organisation. It is a criminal organisation that is not only a threat to the world, but to the lives of its members.\\n\\nThe Islamic State is a criminal organisation that is not', 's prisons on false charges on terrorism. Senator James Lankford is calling for the US to impose sanctions in light of Turkey’s actions.\\n\\nPlease continue to pray for Pastor Brunson and other prisoners of conscience in Turkey. More details in the coming days.\\n\\nThe US has been accused of supporting the coup attempt by Turkey, which has denied the allegations.\\n\\nThe US has been accused of supporting the coup attempt by Turkey, which has denied the allegations.\\n\\nThe US', \" function(){\\n\\t\\t\\tif($(this).hasClass('collapsed')){\\n\\t\\t\\t\\t$(this)\\n\\t\\t\\t\\t\\t.removeClass('collapsed')\\n\\t\\t\\t\\t\\t.siblings()\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n}\\n\", ' academic rigor in my classroom, I have always believed and practiced academic engagement while lecturing, I believe in experiential teaching-learning. I truly believe that education is interdisciplinary; therefore I have successfully guided 15 students for their PhD degree across disciplines. I have also been a leader in the field of teaching and learning, and have been a leader in the field of teaching and learning for over 20 years. I have been a leader in the field of teaching and learning for over 20 years.', ' phosphorus in the formulation as P2O5; and (3) K—the amount of potassium in the formulation as K2O. Nitrogen, phosphorus and potassium are the basic plant nutrients or macronutrients that are taken up and utilized by plants. The amount of nitrogen, phosphorus and potassium in the formulation is determined by the amount of nitrogen, phosphorus and potassium in the formulation. The amount of nitrogen, phosphorus and potassium in the formulation is determined by the amount of nitrogen, phosphorus and']\n"
     ]
    }
   ],
   "source": [
    "model_eval(model, c_toks_NI, c_orig_pred_NI, k_toks_NI, k_orig_pred_NI, I_range=[50,100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cd9588c5-0383-452e-9a3c-3788049d983c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_topK_grads(model, topK:float=0.001, abs_grad:bool=True, c_types:list=[\"W_in\", \"W_out\", \"W_K\", \"W_V\", \"W_Q\", \"W_O\"]):\n",
    "    \"\"\"\n",
    "    find the topK weights in all model parameters\n",
    "    \"\"\"\n",
    "    ## (1) collect all params\n",
    "    all_params = list()\n",
    "    all_params = torch.cat([param.grad.view(-1) for name, param in model.named_parameters() if name.split(\".\")[-1] in c_types])\n",
    "    if abs_grad:\n",
    "        all_params = torch.abs(all_params)\n",
    "\n",
    "    ## (2) identify top params (sparsity)\n",
    "    if 0.0 < topK < 1.0: ## percentage\n",
    "        topk_vals, topk_idcs = torch.topk(all_params, k=int(topK*len(all_params)), largest=True)\n",
    "    elif 1.0 <= topK < len(all_params): ## pick top weights\n",
    "        topk_vals, topk_idcs = torch.topk(all_params, k=int(topK), largest=True)\n",
    "    min_grad = torch.min(topk_vals)\n",
    "    print(f\"{len(topk_idcs)} weights in {c_types} with grads > {min_grad.item()} abs_grad: {abs_grad}\")\n",
    "    return min_grad, topk_idcs\n",
    "\n",
    "def clip_grads(model, min_grad:float, keep_neg:bool=True): ## in-place\n",
    "    \"\"\"\n",
    "    clip gradients than are not above min_grad, and not below min_grad if keep_neg is enabled\n",
    "    \"\"\"\n",
    "    #param_vec = torch.nn.utils.parameters_to_vector(model.parameters())\n",
    "    #torch.nn.utils.vector_to_parameters(param_vec, model.parameters())\n",
    "    print(f\"clipped at {min_grad} with keep_neg: {keep_neg}\")\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            if keep_neg: ## keep very small and very big gradients\n",
    "                param.grad[(0 < param.grad) & (param.grad < min_grad)] = 0.0 ## annul small positive\n",
    "                param.grad[(0 > param.grad) & (param.grad > -min_grad)] = 0.0 ## annul small negative\n",
    "            else: ## keep only very big gradients\n",
    "                param.grad[(param.grad < min_grad)] = 0.0 ## annul all grads smaller than min_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "87113bac-0afd-4f74-b98e-9acf7099d942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset model gpt2-medium\n",
      "Loaded pretrained model gpt2-medium into HookedTransformer\n",
      "added optimizer with lr: 0.0001 and weight_decay: 0.01\n",
      "contrast_res: -5.291677474975586, c_nll: 5.291677474975586, k_nll: 0.0\n",
      "1000 weights in ['W_in', 'W_out'] with grads > 2.8466906547546387 abs_grad: True\n",
      "clipped at 2.8466906547546387 with keep_neg: True\n",
      "optimizer step to change model params\n"
     ]
    }
   ],
   "source": [
    "def run_fwd_bwd(model, metric_fn, c_toks_NI:torch.LongTensor=None, k_toks_NI:torch.LongTensor=None, optim_step:bool=False, topK:float=None, grad_norm:float=None, c_types:list=None):\n",
    "    \"\"\"\n",
    "    adding hooks to model, running model on data on metric and returning cached activs, params are cached in model\n",
    "    \"\"\"\n",
    "    fwd_cache, bwd_cache = gradient.add_fwd_bwd_hooks(model, hook_filter={\"not in\":\"_input\"})\n",
    "    c_nll = modelHandlers.gather_token_scores(modelHandlers.NegLogLik(model(c_toks_NI.to(model.cfg.device))).to(\"cpu\"), c_toks_NI)\n",
    "    k_nll = modelHandlers.gather_token_scores(modelHandlers.NegLogLik(model(k_toks_NI.to(model.cfg.device))).to(\"cpu\"), k_toks_NI)    \n",
    "    metric_res, metric_norm = metric_fn(c_nll, k_nll)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    metric_res.backward(retain_graph=False)\n",
    "    \n",
    "    if grad_norm is not None:\n",
    "        print(f\"applied grad norm clipping with max norm {grad_norm}\")\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), float(grad_norm), norm_type=2.0)\n",
    "               \n",
    "    topk_idcs = None\n",
    "    if topK is not None:\n",
    "        min_grad, topk_idcs = find_topK_grads(model, topK=topK, c_types=c_types, abs_grad=True)\n",
    "        clip_grads(model, min_grad, keep_neg=True)\n",
    "    \n",
    "    if optim_step and hasattr(model, 'optim'):\n",
    "        print(f\"optimizer step to change model params\")\n",
    "        model.optim.step()\n",
    "        model.optim.zero_grad()\n",
    "\n",
    "    fwd_cache = transformer_lens.ActivationCache(fwd_cache, model)\n",
    "    bwd_cache = transformer_lens.ActivationCache(bwd_cache, model)\n",
    "    return fwd_cache, bwd_cache, topk_idcs\n",
    "\n",
    "model = modelHandlers.load_model(model, lr=0.0001, weight_decay=0.01)\n",
    "metric_fn = functools.partial(gradient.contrast_metric, I_range=[50,100], with_mse=True, pool={\"c\":[0],\"k\":[0]}, norm_sets=1.0)\n",
    "fwd_bwd_fn = functools.partial(run_fwd_bwd, optim_step=True, topK=1000, grad_norm=None, c_types=[\"W_in\", \"W_out\"])#, \"W_K\",\"W_V\",\"W_Q\"])\n",
    "fwd_cache, bwd_cache, topk_idcs = fwd_bwd_fn(model, metric_fn, c_toks_NI, k_toks_NI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7868c62e-55ca-484e-961f-19ed9c380538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a402f2cc60e44d8b183aa9c40c4719a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26051c6b8288493fb4b3ace1036d634a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Greedy EM--- change set: 1.0, keep set: 6.599999904632568  [mean over 5 seqs]\n",
      "---Mean NLL--- change set: 7.4672, keep set: 8.0368\n",
      "c_NI_pred: [' is currently unavailable. Please, try again later. View profileView wishlistStart conversationInvite to friendsInvite to friendsAccept invitationAccept invitationPending invitation...User since {{ user.formattedDateUserJoined }} Friends since {{ user.formatted\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "k_NI_pred: [' Islam. They either rape them or sell them on for £10 or so to new masters. The girls are the victims of slavery, child abuse and forced marriage. Their captors are by extension slavers and rapists.\\n\\nAs you can see\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', 's prisons on false charges on terrorism. Senator James Lankford is calling for the US to impose sanctions in light of Turkey’s actions.\\n\\nPlease continue to pray for Pastor Brunson and other prisoners of conscience in Turkey. More details in\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', \" function(){\\n\\t\\t\\tif($(this).hasClass('collapsed')){\\n\\t\\t\\t\\t$(this)\\n\\t\\t\\t\\t\\t.removeClass('collapsed')\\n\\t\\t\\t\\t\\t.siblings})\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", ' academic rigor in my classroom, I have always believed and practiced academic engagement while lecturing, I believe in experiential teaching-learning. I truly believe that education is interdisciplinary; therefore I have successfully guided 15 students for their PhD degree across student level\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', ' phosphorus in the formulation as P2O5; and (3) K—the amount of potassium in the formulation as K2O. Nitrogen, phosphorus and potassium are the basic plant nutrients or macronutrients that are taken up and utilized\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n"
     ]
    }
   ],
   "source": [
    "model_eval(model, c_toks_NI, c_orig_pred_NI, k_toks_NI, k_orig_pred_NI, I_range=[50,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bfd8c0fb-f938-408a-9bfd-abb17c396530",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = modelHandlers.load_model(model, lr=0.0, weight_decay=0.01)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m k_preds_NI, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodelHandlers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_toks_NI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_toks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m em \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mcompute_exact_match(k_preds_NI, k_preds_orig, until_wrong\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeep exact match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/paraMem/utils/modelHandlers.py:90\u001b[0m, in \u001b[0;36mbatch_decode\u001b[0;34m(model, toks_NI, dl, n_batch, start_at_tok, new_toks, do_sample)\u001b[0m\n\u001b[1;32m     88\u001b[0m toks_NI \u001b[38;5;241m=\u001b[39m k_toks_NI\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;66;03m## detach and put on device\u001b[39;00m\n\u001b[1;32m     89\u001b[0m toks_NI_pref, toks_NI_true \u001b[38;5;241m=\u001b[39m toks_NI[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,:start_at_tok], toks_NI[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m-\u001b[39mstart_at_tok:]\n\u001b[0;32m---> 90\u001b[0m toks_NI_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoks_NI_pref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_toks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_at_eos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m toks_NI_pred \u001b[38;5;241m=\u001b[39m toks_NI_pred[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m-\u001b[39mnew_toks:] \u001b[38;5;66;03m## only take continuations  \u001b[39;00m\n\u001b[1;32m     92\u001b[0m preds_NI\u001b[38;5;241m.\u001b[39mappend(toks_NI_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformer_lens/HookedTransformer.py:1901\u001b[0m, in \u001b[0;36mHookedTransformer.generate\u001b[0;34m(self, input, max_new_tokens, stop_at_eos, eos_token_id, do_sample, top_k, top_p, temperature, freq_penalty, use_past_kv_cache, prepend_bos, padding_side, return_type, verbose)\u001b[0m\n\u001b[1;32m   1898\u001b[0m         return_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1900\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tokens, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m-> 1901\u001b[0m batch_size, ctx_length \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1902\u001b[0m device \u001b[38;5;241m=\u001b[39m devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m   1903\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "#model = modelHandlers.load_model(model, lr=0.0, weight_decay=0.01)\n",
    "k_preds_NI, _ = modelHandlers.batch_decode(model, k_toks_NI, new_toks=50)\n",
    "em = evaluation.compute_exact_match(k_preds_NI, k_preds_orig, until_wrong=False)\n",
    "print(f\"keep exact match: {em}\")\n",
    "model.to_string(k_preds_NI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5aea5667-6821-481b-a1b3-e6f1e86690a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ombia); CERN, CERN-CAS, and CERN-CAS-CAS (Colombia); CERN-CAS-CAS-CAS (Colombia); CERN-CAS-CAS',\n",
       " ' ());\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n\\n}\\n',\n",
       " 'W5hbWVzdGFuZS5jb20vb2VudHMudGhlbWVzdGFuZS5jb20vb2VudHMudGhlbWV',\n",
       " 'Linux is a free operating system that runs on a variety of hardware. It is a free operating system that runs on a variety of hardware. It is a free operating system that runs on a variety of hardware.\\n\\nLinux is a free operating system',\n",
       " ' and the cultivars are selected for their ability to withstand the stresses of the growing season.\\n\\nThe selection of cultivars is based on the following criteria:\\n\\nThe cultivars are selected for their ability to withstand the stresses of the growing season',\n",
       " '                                                  ',\n",
       " ', and are often the subject of a great deal of discussion.\\n\\nThe book is divided into three parts, each of which is divided into chapters. The first part, The General Prologue, is a collection of short stories, each of which',\n",
       " ' a spider boy, you are going to have to dig deep for a bigger set of balls.\" \"I\\'m not going to dig deep for a bigger set of balls.\" \"I\\'m not going to dig deep for a bigger set of balls.\" \"',\n",
       " 'etype=\"progress\"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span',\n",
       " '2NvbS9zdGF0ZS1vbS9zdGF0ZS1vbS9zdGF0ZS1vbS9zdGF0ZS1vbS9']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_string(k_preds_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "133fd202-05df-42ce-a935-997ee1c7aeba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271f9cb5fdfe4b0ba17a2b1f397f9bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change exact match: tensor([5.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['istration.py:1062\\n\\nmsgstr \"\"\\n\\n#: ../server/handlers/xmlrpc/registration.py:1063\\n\\nmsgstr \"\"\\n\\n#: ../server/handlers/xml']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_preds_NI, c_preds_NI_true = modelHandlers.batch_decode(model, c_toks_NI)\n",
    "em = evaluation.compute_exact_match(c_preds_NI, c_preds_NI_true, until_wrong=False)\n",
    "print(f\"change exact match: {em}\")\n",
    "model.to_string(c_preds_NI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65da127c-5060-4c69-a8ff-a42de4800bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'istration.py:1071\\nmsgid \"Red Hat Satellite Privacy Statement\"\\nmsgstr \"\"\\n\\n#: ../server/handlers/xmlrpc/registration.py:1092\\nmsgid \"Expected a dictionary'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_string(c_toks_NI[:,:,50:].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f948446-2c6b-4370-b691-bab7f2574bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7f915a",
   "metadata": {},
   "source": [
    "\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d70f2e-2d26-4b1e-9904-221277fc9883",
   "metadata": {
    "id": "59d70f2e-2d26-4b1e-9904-221277fc9883"
   },
   "source": [
    "# Intervened Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a2b45-0a48-4ec4-b231-b54bd9ffbecc",
   "metadata": {
    "id": "385a2b45-0a48-4ec4-b231-b54bd9ffbecc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import torch, gc, itertools, tqdm, scipy, copy, functools, collections, transformer_lens\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import modelHandlers, dataLoaders, gradient, intervening, localizing, evaluation\n",
    "modelHandlers.gpu_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73414b4-289e-4b9e-afe2-80af0af1ee40",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68924f4c-abd1-4f40-a659-36d67d71e064",
   "metadata": {
    "id": "68924f4c-abd1-4f40-a659-36d67d71e064",
    "outputId": "856915ea-112a-49d7-95ec-eac0b12c730f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"gpt-neo-125M\"\n",
    "model = modelHandlers.load_model(model_type=model_type, DEVICE=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5fff3-11da-4435-a593-3aab22abe1c9",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b28205-2803-49dc-867e-1a0380dc0e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mem_nonmem_sets  = dataLoaders.load_pile_splits(f\"{model_type}/preds\", file_names=[\"50_50_preds.pt\", \"0_10_preds.pt\"], as_torch=True)\n",
    "mem_set, non_mem_set = mem_nonmem_sets[0], mem_nonmem_sets[1]\n",
    "train_dl, test_dl = dataLoaders.train_test_batching(mem_set, non_mem_set, mem_batch=1, non_mem_batch=30, test_frac=0.2, add_bos=None)\n",
    "c_toks_NI, k_toks_NI = next(iter(train_dl))\n",
    "c_toks_NI, k_toks_NI = c_toks_NI.squeeze(0), k_toks_NI.squeeze(0)\n",
    "\n",
    "## load perturbed mem set and original mem set\n",
    "#mem_perturbed_sets  = dataLoaders.load_pile_splits(f\"{model_type}/perturbed\", file_names=[\"mem_toks.pt\", \"perturbed_mem_toks.pt\"], as_torch=True)\n",
    "#mem_set, perturbed_mem_set = mem_perturbed_sets[0], mem_perturbed_sets[1]\n",
    "#train_dl, test_dl = dataLoaders.train_test_batching(mem_set, perturbed_mem_set, mem_batch=20, non_mem_batch=20, test_frac=0.2, add_bos=None)\n",
    "#c_toks_NI, c_perturb_toks_NI = next(iter(train_dl))\n",
    "#c_toks_NI, c_perturb_toks_NI, = c_toks_NI.squeeze(0), c_perturb_toks_NI.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e3000-83c7-4f5d-8253-65d9cbe79a13",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "479886ddaaf44c98b6cd1a1e048c4a91"
     ]
    },
    "id": "061e3000-83c7-4f5d-8253-65d9cbe79a13",
    "outputId": "a24c4572-f7f4-42b3-a56e-e3ce62cbcc67",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_eval(model,c_NI:torch.LongTensor=None,k_NI:torch.LongTensor=None,I_range:list=[50,100], print_pred:bool=True):\n",
    "    \"\"\"\n",
    "    evaluate the language model on individual batches of c_toks_NI and k_toks_NI\n",
    "    \"\"\"\n",
    "    (c_mean_nll, c_minK_nll), (c_NI_pred, c_NI_true) = evaluation.evaluate_nll_greedy(model, c_NI, batch_size=50)\n",
    "    (k_mean_nll, k_minK_nll), (k_NI_pred, k_NI_true) = evaluation.evaluate_nll_greedy(model, k_NI, batch_size=50)\n",
    "\n",
    "    c_em_N = evaluation.compute_exact_match(c_NI_pred, c_NI_true, until_wrong=True)\n",
    "    k_em_N = evaluation.compute_exact_match(k_NI_pred, k_NI_true, until_wrong=True)\n",
    "\n",
    "    ## process change and keep set\n",
    "    c_mean_nll, k_mean_nll = round(c_mean_nll[...,I_range[0]:I_range[1]].mean().detach().item(),4), round(k_mean_nll[...,I_range[0]:I_range[1]].mean().detach().item(),4)\n",
    "    \n",
    "    c_changed_frac = torch.where(c_em_N == int(I_range[1]-I_range[0]), 0, 1).sum()\n",
    "    k_kept_frac = torch.where(k_em_N == int(I_range[1]-I_range[0]), 1, 0).sum() \n",
    "\n",
    "    print(f\"---Greedy EM--- change set: {c_em_N.mean().item()} [changed {c_changed_frac}/{c_em_N.shape[0]}], keep set: {k_em_N.mean().item()} [kept {k_kept_frac}/{k_em_N.shape[0]}]\")\n",
    "    print(f\"---Mean NLL--- change set: {c_mean_nll}, keep set: {k_mean_nll}\\n\\n\")\n",
    "    \n",
    "    if print_pred:\n",
    "        print(f\"c_NI_pred: {model.to_string(c_NI_pred)}\\n\")\n",
    "        print(f\"k_NI_pred: {model.to_string(k_NI_pred)}\")\n",
    "        \n",
    "    return (c_em_N, k_em_N), (c_mean_nll, k_mean_nll)\n",
    "            \n",
    "#model_eval(model, c_toks_NI, c_orig_pred_NI, k_toks_NI, k_orig_pred_NI, I_range=[50,100])\n",
    "(c_em_N, k_em_N), (c_mean_nll, k_mean_nll) = model_eval(model, c_toks_NI, k_toks_NI, I_range=[50,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03202d6b-9357-4feb-b9db-69dc5223024a",
   "metadata": {},
   "source": [
    "## With Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd68a0-7e37-4bcb-8a68-3605dffca091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = modelHandlers.load_model(model, lr=0.0, weight_decay=1.0)\n",
    "metric_fn = functools.partial(gradient.contrast_metric, I_range=[49,99], use_perturb=False, c_set_norm=0.1)\n",
    "fwd_bwd_fn = functools.partial(gradient.run_contrastive_fwd_bwd, optim_steps=-1, topK=None, grad_norm=None, c_types=[\"W_V\",\"W_Q\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]) \n",
    "fwd_cache, bwd_cache, topk_idcs = fwd_bwd_fn(model, metric_fn, c_toks_NI, c_toks_NI, k_toks_NI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb935298-9c1d-4b0c-a7db-41973da8c91d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def c_type_collection(model, bwd_cache=None, c_types:list=[\"W_Q\",\"W_K\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]):\n",
    "    \"\"\"\n",
    "    summing all gradient weights in component c_type over multiple batches\n",
    "    \"\"\"\n",
    "    weight_gradients = collections.defaultdict(torch.tensor)\n",
    "    for c_type in c_types:\n",
    "        if c_type in [\"W_Q\",\"W_K\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]: ## model params\n",
    "            c_vals, c_names = localizing.collect_c_type(model=model, cache=None, c_type=c_type)\n",
    "        elif c_type in [\"q\",\"k\",\"v\",\"o\",\"mlp_in\",\"mlp_out\"]: ## activation\n",
    "            c_vals, c_names = localizing.collect_c_type(model=model, cache=bwd_cache, c_type=c_type)\n",
    "        else:\n",
    "            raise Exception(f\"No eligible parameter oder activation name passed: {c_types}\")\n",
    "\n",
    "        ## Summing up values___________________________\n",
    "        c_vals = c_vals.detach() \n",
    "        weight_gradients[c_type] = c_vals \n",
    "    return weight_gradients\n",
    "\n",
    "c_weights = c_type_collection(model, c_types=[\"W_Q\",\"W_K\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7ea18-544b-44ae-9430-6ed0c456afa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_topK_grads(c_grads:dict, topK:int=100, select_c:list=None, select_l:list=None, select_heads:list=[], return_lk:bool=False, largest:bool=True, select_random:bool=False):\n",
    "    \"\"\"\n",
    "    weight_gradients is a list of tensors, collect topK weight gradients and return as layer-wise list and in original shape\n",
    "    \"\"\"\n",
    "    c_grads = copy.deepcopy(c_grads)\n",
    "    ## (1) prepare components and layers\n",
    "    n_layers = list(c_grads.values())[0].shape[0]\n",
    "    if select_l is None or len(select_l) == 0:\n",
    "        select_l = list(range(n_layers))\n",
    "    remove_layers = list(range(n_layers))\n",
    "    remove_layers = list(set(remove_layers).difference(set(select_l)))\n",
    "    if select_c is None or len(select_c) == 0:\n",
    "        select_c = list(c_grads.keys())\n",
    "        \n",
    "    ## (2) gather the top gradients\n",
    "    c_top_grads = {}\n",
    "    for c_type,c_vals in c_grads.items():\n",
    "        if c_type in select_c:\n",
    "            if len(select_heads) > 0 and len(c_vals.shape) >= 4: ##select specific head from attention component \n",
    "                print(c_vals.shape)\n",
    "                c_vals = c_vals[:,torch.LongTensor(select_heads),:,:]\n",
    "            gradients_ld = c_vals.view(c_vals.shape[0],-1) ## flatten tensor to l_dim and model_dim\n",
    "            gradients_ld[torch.LongTensor(remove_layers),:] = gradients_ld[torch.LongTensor(remove_layers),:]*0 ## filter layers based on select_layers criterion  \n",
    "            if select_random==False: ## normal topK selection mode\n",
    "                gradients_ld = torch.abs(gradients_ld)\n",
    "                if 0.0 < topK< 1.0: ## percentage\n",
    "                    topK = int(topK*len(gradients_ld.flatten()))\n",
    "                weight_scores, weight_idcs = torch.topk(gradients_ld.flatten(), topK, largest=largest)\n",
    "            else: ## selecting any random weights as a baseline\n",
    "                random_idcs = torch.randperm(gradients_ld.flatten().shape[0])\n",
    "                weight_scores, weight_idcs = gradients_ld.flatten()[random_idcs[:topK]], random_idcs[:topK].squeeze()\n",
    "            weight_idcs = torch.tensor(np.array(np.unravel_index(weight_idcs.numpy(), gradients_ld.shape))).T\n",
    "            c_top_grads[c_type]={\"idcs\": weight_idcs, \"scores\": weight_scores}\n",
    "\n",
    "            if return_lk: ## reformat the output to return layer-wise list of lists\n",
    "                weight_ids_lk = [[] for l in range(n_layers)]\n",
    "                weight_scores_lk = [[] for l in range(n_layers)]\n",
    "                for k, weight_idx in enumerate(weight_idcs):\n",
    "                    weight_ids_lk[weight_idx[0]].append(weight_idx[1].item())\n",
    "                    weight_scores_lk[weight_idx[0]].append(weight_scores[k].item())\n",
    "                c_top_grads[c_type]={\"idcs\": weight_ids_lk, \"scores\": weight_scores_lk}\n",
    "    return c_top_grads\n",
    "\n",
    "\n",
    "c_weights_lk = get_topK_grads(c_weights, topK=100, select_c=[], select_l=[], select_heads=[], return_lk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24906fee-ddf8-4031-bc94-071cf59203ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_params(model, c_weights_lk:dict, std_fac:float=1.0):\n",
    "    \"\"\"\n",
    "    perform intervention on model params according to weight_ids_LK\n",
    "    \"\"\"\n",
    "    n_weights, layers = 0, []\n",
    "    model = modelHandlers.load_model(model) ## reloading the model\n",
    "    for name, param in model.named_parameters():\n",
    "        name_list = name.split(\".\")\n",
    "        c_type = name_list[-1]\n",
    "        if c_type in c_weights_lk.keys():\n",
    "            l, param_shape = int(name_list[1]), param.shape\n",
    "            weight_ids = torch.LongTensor(c_weights_lk[c_type][\"idcs\"][l])\n",
    "            if len(weight_ids) > 0:\n",
    "                multidim_ids = np.array(np.unravel_index(weight_ids, param_shape)).T\n",
    "                multidim_ids = torch.LongTensor(multidim_ids)\n",
    "        \n",
    "                with torch.no_grad():   \n",
    "                    #std = torch.abs(param[multidim_ids[:,0], multidim_ids[:,1]] * std_fac)\n",
    "                    std = torch.std(param) * std_fac\n",
    "                    set_vals = torch.normal(mean=0.0, std=torch.ones(multidim_ids.shape[0]) * std)                    \n",
    "                    #std = torch.std(param[multidim_ids[:,0]])\n",
    "                    #set_vals = torch.normal(mean=0.0,std=torch.ones(multidim_ids.shape[0])*std*std_fac)\n",
    "                    if multidim_ids.shape[1]==2:\n",
    "                        param[multidim_ids[:,0], multidim_ids[:,1]] += set_vals\n",
    "                    elif multidim_ids.shape[1]==3:\n",
    "                        param[multidim_ids[:,0], multidim_ids[:,1], multidim_ids[:,2]] += set_vals\n",
    "                    n_weights += multidim_ids.shape[0]\n",
    "                    layers.append(l)\n",
    "    print(f\"intervened with {std_fac} on a total of {n_weights} weights in {list(c_weights_lk.keys())} in layers {set(layers)}\")\n",
    "    model.cfg.intervention = {\"std\":std_fac,\"n_weights\":n_weights,\"c_types\":list(c_weights_lk.keys())}\n",
    "    return model\n",
    "\n",
    "model = intervene_params(model, c_weights_lk, std_fac=0.1)\n",
    "ck_em_after, ck_nll_after = model_eval(model, c_toks_NI, k_toks_NI, I_range=[49,99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03392c-8e00-4670-a8c1-7b99e3fe6b32",
   "metadata": {},
   "source": [
    "## Intervention (1): Loop over Different Intervention Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46bcc3b-297a-473c-b948-90affd34c5ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loop_vals_intervention(model, dl, c_weights:list, val_space:tuple=(-5,5,5), topK:int=1000, select_c:list=[], select_l:list=[], select_heads:list=[]):\n",
    "    \"\"\"\n",
    "    searching for best intervention setting by iterating over ideal intervention values\n",
    "    \"\"\"\n",
    "    c_weights_lk = get_topK_grads(c_weights, topK=topK, select_c=select_c, select_l=select_l, select_heads=[], return_lk=True, select_random=False)\n",
    "    intervene_vals = torch.linspace(val_space[0], val_space[1], steps=val_space[2])\n",
    "    ## Ensure that 0 and 1 are always included\n",
    "    #values_to_add = torch.tensor([0, 1])[~torch.isin(torch.tensor([0, 1]), intervene_vals)]\n",
    "    #intervene_vals = torch.cat([intervene_vals, values_to_add]) \n",
    "    #intervene_vals = torch.sort(intervene_vals).values\n",
    "    \n",
    "    ck_em_after, ck_nll_after = [],[]\n",
    "    for intervene_val in tqdm.tqdm(intervene_vals):\n",
    "        model = intervene_params(model, c_weights_lk, std_fac=intervene_val)\n",
    "        ck_em, ck_nll = model_eval(model, c_toks_NI, k_toks_NI, I_range=[49,99])\n",
    "        ck_em = (ck_em[0].mean(),ck_em[1].mean())\n",
    "        ck_em_after.append(ck_em)\n",
    "        ck_nll_after.append(ck_nll)\n",
    "    ck_em_after, ck_nll_after = torch.tensor(ck_em_after), torch.tensor(ck_nll_after)\n",
    "    return ck_em_after, ck_nll_after, intervene_vals, model\n",
    "\n",
    "\n",
    "#\"W_K\",\"W_Q\", \"W_O\",\"W_in\",\"W_out\"2\n",
    "ck_em, ck_nll, intervene_vals, model = loop_vals_intervention(model, train_dl, c_weights, val_space=(0.0,0.0075,6), topK=0.001, select_c=[\"W_K\",\"W_Q\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"], select_l=[], select_heads=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951ea2f7-1666-41f7-aa4d-f5d4d831433e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fontsize = 11\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4.6, 1.5), gridspec_kw={'hspace': 0.4})\n",
    "\n",
    "c_em = ax.scatter(intervene_vals, ck_em[:,0].numpy(), c=\"red\", marker=\"v\", label=\"change set em\")\n",
    "k_em = ax.scatter(intervene_vals, ck_em[:,1].numpy(), c=\"blue\", marker=\"^\", label=\"keep set em\")\n",
    "#ax.axvline(x=0, color='r', linestyle='-', c=\"black\", alpha=0.2)\n",
    "#ax.axhline(y=ck_em[0,1], color='r', linestyle='--', c=\"black\", alpha=0.5)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "c_nll, = ax2.plot(intervene_vals.numpy(), ck_nll[:,0].numpy(), c=\"red\", alpha=0.3, label=\"memorized paragraphs\")\n",
    "k_nll, = ax2.plot(intervene_vals.numpy(), ck_nll[:,1].numpy(), c=\"blue\", alpha=0.3, label=\"non-memorized paragraphs\")\n",
    "#ax.axhline(y=ck_nll[int(ck_nll.shape[0]/2),1], color='r', linestyle='--', c=\"blue\", alpha=0.5)\n",
    "\n",
    "\n",
    "locator = mpl.ticker.MaxNLocator(5)\n",
    "plt.gca().xaxis.set_major_locator(locator)\n",
    "\n",
    "plot_summary = f\"Intervening on 0.1% of max gradient weights\" #{model.cfg.intervention['n_weights']}, {', '.join(model.cfg.intervention['c_types'])}\n",
    "#plot_summary = f\"Intervening on top {model.cfg.intervention['n_weights']} max gradient weights {model.cfg.intervention['c_types']} in layers: {', '.join((str(l) for l in model.cfg.intervention['layers']))}\"\n",
    "ax.set_title(plot_summary, fontsize=fontsize, loc=\"left\", x=-0.1)\n",
    "ax.set_xlabel('std of intervention noise', x=0.8, fontsize=fontsize)\n",
    "\n",
    "ax.set_ylabel('EM (triangles)', fontsize=fontsize) #\\bullet\n",
    "ax2.set_ylabel('NLL (lines)', fontsize=fontsize) #\\searrow\n",
    "#legend = ax.legend(handles=[c_nll, k_nll], frameon=False, bbox_to_anchor=(0.2, -0.15), ncol=2, prop={'size': fontsize}, handlelength=0)\n",
    "#for text, color in zip(legend.get_texts(), [\"red\", \"blue\"]):\n",
    "#    text.set_color(color) \n",
    "\n",
    "ax.text(-0.15, -0.31, f'memorized', color=\"red\", fontsize=fontsize-1, horizontalalignment='left',verticalalignment='center', transform=ax.transAxes)\n",
    "ax.text(0.1, -0.32, f'non-memorized', color=\"blue\", fontsize=fontsize-1, horizontalalignment='left',verticalalignment='center', transform=ax.transAxes)\n",
    "    \n",
    "fig.savefig(f\"{dataLoaders.ROOT}/results/noise_intervention_std.pdf\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168546f-6dee-48ee-8018-c0f52cfc5804",
   "metadata": {},
   "source": [
    "## Intervention (2): Loop over Different Number of Weights set to Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784a49d-94b9-4177-a5c0-e2e5d8e5e254",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loop_topK_intervention(model, dl, c_weights:dict, topK_space:tuple=(-5,5,5), intervene_val:int=0, select_c:list=[], select_l:list=[], select_heads:list=[], largest:bool=True):\n",
    "    \"\"\"\n",
    "    searching for best intervention setting by iterating over ideal intervention values\n",
    "    \"\"\"\n",
    "    topK_vals = torch.linspace(topK_space[0], topK_space[1], steps=topK_space[2])    \n",
    "    ck_em_after, ck_nll_after = [],[]\n",
    "    for topK_val in tqdm.tqdm(topK_vals):\n",
    "        c_weights_lk = get_topK_grads(c_weights,topK=int(topK_val),select_c=select_c,select_l=select_l,select_heads=select_heads,return_lk=True,largest=largest,select_random=False)\n",
    "        model = intervene_params(model, c_weights_lk, std_fac=intervene_val)\n",
    "        ck_em, ck_nll = model_eval(model, c_toks_NI, k_toks_NI, I_range=[49,99])\n",
    "        ck_em = (ck_em[0].mean(),ck_em[1].mean())\n",
    "        ck_em_after.append(ck_em)\n",
    "        ck_nll_after.append(ck_nll)\n",
    "    ck_em_after, ck_nll_after = torch.tensor(ck_em_after), torch.tensor(ck_nll_after)\n",
    "    return ck_em_after, ck_nll_after, topK_vals, model\n",
    "\n",
    "intervene_val = 0.2\n",
    "ck_em, ck_nll, topK_vals, model = loop_topK_intervention(model, train_dl, c_weights, topK_space=(0,100,4), intervene_val=intervene_val, select_c=[\"W_V\"], select_l=[1], select_heads=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cae9a0-4c3b-4d18-b198-89c27e7f11dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fontsize = 9\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 1.5), gridspec_kw={'hspace': 0.4})\n",
    "\n",
    "c_em = ax.scatter(topK_vals, ck_em[:,0].numpy(), c=\"red\", marker=\"v\", label=\"change set em\")\n",
    "k_em = ax.scatter(topK_vals, ck_em[:,1].numpy(), c=\"blue\", marker=\"^\", label=\"keep set em\")\n",
    "#ax.axhline(y=ck_nll[0,1], color='r', linestyle='--', c=\"blue\", alpha=0.5)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "c_nll, = ax2.plot(topK_vals, ck_nll[:,0].numpy(), c=\"red\", alpha=0.3, label=\"memorized\")\n",
    "k_nll, = ax2.plot(topK_vals, ck_nll[:,1].numpy(), c=\"blue\", alpha=0.3, label=\"non-memorized\")\n",
    "\n",
    "plot_summary = f\"Intervening on top {int(topK_vals[0])} to {int(topK_vals[-1])} max gradient weights of {', '.join(model.cfg.intervention['c_types'])} with std of {intervene_val}\"\n",
    "#plot_summary = f\"Intervening on top {model.cfg.intervention['n_weights']} max gradient weights {model.cfg.intervention['c_types']} in layers: {', '.join((str(l) for l in model.cfg.intervention['layers']))}\"\n",
    "ax.set_xlim(topK_vals[0]-2,topK_vals[-1]+2)\n",
    "ax.set_title(plot_summary, fontsize=fontsize, loc=\"left\", x=-0.1)\n",
    "ax.set_xlabel('number of intervention weights', x=0.7, fontsize=fontsize)\n",
    "ax.set_ylabel('EM (triangles)', fontsize=fontsize) #\\bullet\n",
    "ax2.set_ylabel('NLL (lines)', fontsize=fontsize) #\\searrow\n",
    "#legend = ax.legend(handles=[c_nll, k_nll], frameon=False, bbox_to_anchor=(0.2, -0.15), ncol=2, prop={'size': fontsize}, handlelength=0)\n",
    "#for text, color in zip(legend.get_texts(), [\"red\", \"blue\"]):\n",
    "#    text.set_color(color) \n",
    "\n",
    "ax.text(0.0, -0.31, f'memorized', color=\"red\", fontsize=fontsize-1, horizontalalignment='left',verticalalignment='center', transform=ax.transAxes)\n",
    "ax.text(0.2, -0.31, f'non-memorized', color=\"blue\", fontsize=fontsize-1, horizontalalignment='left',verticalalignment='center', transform=ax.transAxes)\n",
    "    \n",
    "    \n",
    "fig.savefig(f\"{dataLoaders.ROOT}/results/noise_intervention_n_weights.pdf\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f62740-aeec-4be5-9cac-da9849e34ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

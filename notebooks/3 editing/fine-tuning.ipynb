{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0a6cb30",
   "metadata": {},
   "source": [
    "\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcca71b-b72f-4699-b956-1e25929aa311",
   "metadata": {},
   "source": [
    "# Fine-Tuning: Integrate Localization and Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e0feb0-c6bc-4079-9946-32bf0e96f301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import transformer_lens\n",
    "import torch, gc, itertools, functools, tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import modelHandlers, dataLoaders, gradient, evaluation, localizing, intervening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67623921-6d0d-498e-a112-4a2ccccad640",
   "metadata": {},
   "source": [
    "## Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84de32-0f84-4ac8-b393-e45add133d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"gpt-neo-125M\"\n",
    "model = modelHandlers.load_model(model_type=model_type, DEVICE=\"cuda\", lr=0.0, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee438f85-dd13-4d26-b9ac-9078b111f17d",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51b9c7-afac-4957-8db9-44e200599e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## mem and non-mem set\n",
    "mem_nonmem_sets  = dataLoaders.load_pile_splits(f\"{model_type}/preds\", file_names=[\"50_50_preds.pt\", \"0_10_preds.pt\"], as_torch=True)\n",
    "mem_set, non_mem_set = mem_nonmem_sets[0], mem_nonmem_sets[1]\n",
    "train_dl, test_dl = dataLoaders.train_test_batching(mem_set, non_mem_set, mem_batch=1, non_mem_batch=10, test_frac=0.2, add_bos=None)\n",
    "_, k_toks_NI = next(iter(train_dl))\n",
    "k_toks_NI = k_toks_NI.squeeze(0)\n",
    "\n",
    "## load perturbed mem set and original mem set\n",
    "mem_perturbed_sets  = dataLoaders.load_pile_splits(f\"{model_type}/perturbed\", file_names=[\"mem_toks.pt\", \"perturbed_mem_toks.pt\"], as_torch=True)\n",
    "mem_set, perturbed_mem_set = mem_perturbed_sets[0], mem_perturbed_sets[1]\n",
    "train_dl, test_dl = dataLoaders.train_test_batching(mem_set, perturbed_mem_set, mem_batch=10, non_mem_batch=10, matched=True, shuffle=False, test_frac=0.2, add_bos=None)\n",
    "c_toks_NI, c_perturb_toks_NI = next(iter(train_dl))\n",
    "c_toks_NI, c_perturb_toks_NI, = c_toks_NI.squeeze(0), c_perturb_toks_NI.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5794d-7199-44da-983e-9beae9285081",
   "metadata": {},
   "source": [
    "### Generate Original Continuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295a0e6-f7a1-4f02-9f5d-be39b813f151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_eval(model,c_NI:torch.LongTensor=None,k_NI:torch.LongTensor=None,I_range:list=[50,100], print_pred:bool=True):\n",
    "    \"\"\"\n",
    "    evaluate the language model on individual batches of c_toks_NI and k_toks_NI\n",
    "    \"\"\"\n",
    "    (c_mean_nll, c_minK_nll), (c_NI_pred, c_NI_true) = evaluation.evaluate_nll_greedy(model, c_NI, batch_size=50)\n",
    "    (k_mean_nll, k_minK_nll), (k_NI_pred, k_NI_true) = evaluation.evaluate_nll_greedy(model, k_NI, batch_size=50)\n",
    "\n",
    "    c_em_N = evaluation.compute_exact_match(c_NI_pred, c_NI_true, until_wrong=True)\n",
    "    k_em_N = evaluation.compute_exact_match(k_NI_pred, k_NI_true, until_wrong=True)\n",
    "\n",
    "    ## process change and keep set\n",
    "    c_mean_nll, k_mean_nll = round(c_mean_nll[...,I_range[0]:I_range[1]].mean().detach().item(),4), round(k_mean_nll[...,I_range[0]:I_range[1]].mean().detach().item(),4)\n",
    "    \n",
    "    c_changed_frac = torch.where(c_em_N == int(I_range[1]-I_range[0]), 0, 1).sum()\n",
    "    k_kept_frac = torch.where(k_em_N == int(I_range[1]-I_range[0]), 1, 0).sum() \n",
    "\n",
    "    print(f\"---Greedy EM--- change set: {c_em_N.mean().item()} [changed {c_changed_frac}/{c_em_N.shape[0]}], keep set: {k_em_N.mean().item()} [kept {k_kept_frac}/{k_em_N.shape[0]}]\")\n",
    "    print(f\"---Mean NLL--- change set: {c_mean_nll}, keep set: {k_mean_nll}\\n\\n\")\n",
    "    \n",
    "    if print_pred:\n",
    "        print(f\"c_NI_pred: {model.to_string(c_NI_pred)}\\n\")\n",
    "        print(f\"k_NI_pred: {model.to_string(k_NI_pred)}\")\n",
    "        \n",
    "    return c_em_N, k_em_N\n",
    "            \n",
    "#model_eval(model, c_toks_NI, c_orig_pred_NI, k_toks_NI, k_orig_pred_NI, I_range=[50,100])\n",
    "c_em_N, k_em_N = model_eval(model, c_toks_NI, k_toks_NI, I_range=[50,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9588c5-0383-452e-9a3c-3788049d983c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_topK_grads(model, topK:float=0.001, c_types:list=[\"W_K\", \"W_Q\", \"W_V\", \"W_O\",\"W_in\", \"W_out\"]):\n",
    "    \"\"\"\n",
    "    find the topK weights in all model parameters\n",
    "    \"\"\"\n",
    "    ## (1) collect all params\n",
    "    all_param_grads = list()\n",
    "    all_param_grads = torch.cat([torch.abs(param.grad.view(-1)) for name, param in model.named_parameters() if name.split(\".\")[-1] in c_types])\n",
    "\n",
    "    ## (2) identify top params (sparsity)\n",
    "    topK = abs(topK)\n",
    "    if 0.0 < topK< 1.0: ## percentage\n",
    "        topK = int(topK*len(all_param_grads))\n",
    "        \n",
    "    if 1.0 <= topK < len(all_param_grads): ## pick top weights\n",
    "        topk_vals_flat, topk_idcs_flat = torch.topk(all_param_grads, k=int(topK), largest=True)\n",
    "    \n",
    "    min_grad = torch.min(topk_vals_flat)\n",
    "    print(f\"{len(topk_idcs_flat)} weights in {c_types} with grads > {min_grad.item()}\\n\")\n",
    "    return min_grad, topk_idcs_flat\n",
    "\n",
    "\n",
    "def clip_grads(model, min_grad:float=None, full_remove_idcs:list=[], topK=0.0): ## in-place\n",
    "    \"\"\"\n",
    "    clip gradients than are not above min_grad, and not below min_grad if keep_neg is enabled\n",
    "    \"\"\"\n",
    "    #param_vec = torch.nn.utils.parameters_to_vector(model.parameters())\n",
    "    #torch.nn.utils.vector_to_parameters(param_vec, model.parameters())\n",
    "    list_idx = 0\n",
    "    removed_n_weights = 0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            if min_grad is not None:\n",
    "                if -1.0 < topK < 0.0:\n",
    "                    remove_idcs = torch.bernoulli(torch.ones(param.grad.shape)*(1.0-abs(topK)))\n",
    "                else:  \n",
    "                    remove_idcs = torch.where((param.grad >= min_grad) | (param.grad <= -min_grad), 0, 1)\n",
    "                full_remove_idcs.append(remove_idcs)\n",
    "            else:\n",
    "                remove_idcs = full_remove_idcs[list_idx]\n",
    "                list_idx += 1\n",
    "            removed_n_weights += ((~(remove_idcs.bool())).int()).sum()\n",
    "            param.grad[remove_idcs.bool()] = 0.0 ## annul small positive and negative grads\n",
    "            \n",
    "    print(f\"clipped at {min_grad} / kept {removed_n_weights.sum()} weights\")\n",
    "    return full_remove_idcs\n",
    "                \n",
    "                \n",
    "#min_grad, topk_idcs_flat = find_topK_grads(model, topK=0.01)\n",
    "#full_remove_idcs = clip_grads(model, min_grad)\n",
    "#full_remove_idcs = clip_grads(model, min_grad=None, full_remove_idcs=full_remove_idcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b30a8b5-baab-4b44-8fe9-25b47aabc8e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "KLDiv = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "\n",
    "def contrast_metric(c_nll_NIT, c_toks_NI, c_perturb_toks_NI, k_logits_NIT, k_logits_fixed_NIT, I_range:list=[49,99], use_perturb:bool=True, c_set_norm:float=None):\n",
    "    \"\"\"\n",
    "    minimizing / preserve keep_score while maximizing change_score\n",
    "    \"\"\"\n",
    "    \n",
    "    if use_perturb:\n",
    "        c_nll_NI = modelHandlers.gather_token_scores(c_nll_NIT, c_perturb_toks_NI)\n",
    "    else:\n",
    "        c_nll_NI = modelHandlers.gather_token_scores(c_nll_NIT, c_toks_NI)\n",
    "\n",
    "    \n",
    "    c_nll_Nc = c_nll_NI[...,I_range[0]:I_range[1]]\n",
    "    k_logits_NcT, k_logits_fixed_NcT = k_logits_NIT[...,I_range[0]:I_range[1],:], k_logits_fixed_NIT[...,I_range[0]:I_range[1],:]\n",
    "        \n",
    "    keep = KLDiv(F.log_softmax(k_logits_NcT,  dim=-1), F.softmax(k_logits_fixed_NcT.detach(), dim=-1)).mean()\n",
    "    change = c_set_norm * c_nll_Nc.mean()\n",
    "    \n",
    "    if use_perturb:\n",
    "        contrast_res = (keep+change)\n",
    "    else:\n",
    "        contrast_res = (keep-change)\n",
    "        \n",
    "    print(f\"loss: {contrast_res}, mem: {change.detach()}, non mem: {keep.detach()}, use_perturb: {use_perturb}, c_set_norm: {c_set_norm}\")\n",
    "    return contrast_res, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87113bac-0afd-4f74-b98e-9acf7099d942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_contrastive_fwd_bwd(model, metric_fn, c_toks_NI, c_perturb_toks_NI, k_toks_NI, optim_steps:int=-1, topK:float=None, grad_norm:float=None, c_types:list=None):\n",
    "    \"\"\"\n",
    "    adding hooks to model, running model on data on metric and returning cached activs, params are cached in model\n",
    "    \"\"\"\n",
    "    fwd_cache, bwd_cache = gradient.add_fwd_bwd_hooks(model, hook_filter={\"not in\":\"_input\"})     \n",
    "    c_toks_NI = c_toks_NI.to(model.cfg.device)\n",
    "    c_perturb_toks_NI = c_perturb_toks_NI.to(model.cfg.device)\n",
    "    k_toks_NI = k_toks_NI.to(model.cfg.device)\n",
    "    k_logits_fixed_NIT = model(k_toks_NI)\n",
    "\n",
    "    for step_i in range(abs(optim_steps)):\n",
    "        \n",
    "        c_nll_NIT = modelHandlers.NegLogLik(model(c_toks_NI))\n",
    "        k_logits_NIT = model(k_toks_NI)\n",
    "\n",
    "        metric_res, metric_norm = metric_fn(c_nll_NIT, c_toks_NI, c_perturb_toks_NI, k_logits_NIT, k_logits_fixed_NIT) \n",
    "\n",
    "        model.zero_grad()\n",
    "        metric_res.backward(retain_graph=False)\n",
    "\n",
    "        if grad_norm is not None:\n",
    "            print(f\"applied grad norm clipping with max norm {grad_norm}\")\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), float(grad_norm), norm_type=2.0)\n",
    "\n",
    "        if topK is not None:\n",
    "            if step_i == 0:\n",
    "                min_grad, topk_idcs = find_topK_grads(model, topK=topK, c_types=c_types)\n",
    "                full_remove_idcs = clip_grads(model, min_grad, full_remove_idcs=[], topK=topK)\n",
    "            full_remove_idcs = clip_grads(model, min_grad=None, full_remove_idcs=full_remove_idcs)\n",
    "        else:\n",
    "            full_remove_idcs = None\n",
    "\n",
    "        if optim_steps >= 1 and hasattr(model, 'optim'):\n",
    "            print(f\"{step_i+1}/{abs(optim_steps)}, optimizer step\")\n",
    "            model.optim.step()\n",
    "            model.optim.zero_grad()\n",
    "    \n",
    "    del c_toks_NI\n",
    "    del k_toks_NI\n",
    "    del c_perturb_toks_NI\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    fwd_cache = transformer_lens.ActivationCache(fwd_cache, model)\n",
    "    bwd_cache = transformer_lens.ActivationCache(bwd_cache, model)\n",
    "    return fwd_cache, bwd_cache, full_remove_idcs\n",
    "\n",
    "model = modelHandlers.load_model(model, lr=1e-05, weight_decay=1.0)\n",
    "metric_fn = functools.partial(contrast_metric, I_range=[49,99], use_perturb=True, c_set_norm=0.1)\n",
    "fwd_bwd_fn = functools.partial(run_contrastive_fwd_bwd, optim_steps=5, topK=0.01, grad_norm=None, c_types=[\"W_K\",\"W_Q\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"])  #\"W_K\",\"W_Q\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"\n",
    "fwd_cache, bwd_cache, topk_idcs = fwd_bwd_fn(model, metric_fn, c_toks_NI, c_perturb_toks_NI, k_toks_NI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868c62e-55ca-484e-961f-19ed9c380538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_em, k_em = model_eval(model, c_toks_NI, k_toks_NI, I_range=[50,100])\n",
    "#model_eval(model, c_toks_NI, None, k_toks_NI, k_orig_pred_NI, I_range=[50,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10857078-1968-4ebc-ac87-1dfcbfea597d",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f959e86-d378-4f3a-a399-921d76cf6806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_test_NI, k_test_NI = next(iter(test_dl))\n",
    "c_test_NI, k_test_NI = c_test_NI.squeeze(0), k_test_NI.squeeze(0)\n",
    "model_eval(model, c_test_NI, k_test_NI, I_range=[50,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243f4e5-588b-4080-ac71-4007e790b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

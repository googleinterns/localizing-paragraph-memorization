{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4543fc",
   "metadata": {},
   "source": [
    "\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeacd3b-9676-4786-b485-66e016c9cb82",
   "metadata": {},
   "source": [
    "# Mem Set Range Gradients (Activations and Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3b83b-4985-4bcb-ae2c-78cd8d023e69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import transformer_lens, torch, gc, itertools, functools, math, glob, tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LogNorm, SymLogNorm\n",
    "\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.bottom'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import modelHandlers, dataLoaders, gradient, localizing, patching\n",
    "\n",
    "torch.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439948d-afb3-472f-8dde-c0ea88b5b4df",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32953121-1ca8-40ff-96eb-63b822bdfe9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"gpt-neo-125M\"\n",
    "model = modelHandlers.load_model(model_type=model_type, DEVICE=\"cpu\")\n",
    "modelHandlers.set_no_grad(model, [\"embed\", \"pos_embed\", \"unembed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30427e33-f8b3-422e-9768-9180d7f3749e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30435018-6690-478c-b559-8dbf80b03908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "range_data = dataLoaders.load_pile_splits(f\"{model_type}/preds\", file_names=None)\n",
    "range_dl = list(map(lambda toks_NI: torch.utils.data.DataLoader(toks_NI, batch_size=50, shuffle=False), range_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc151634-f609-4cf1-b10b-9cff0d2a8ed7",
   "metadata": {},
   "source": [
    "### Run backprop and gather gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3e352-d2d6-453d-b4d2-d1cb38ded27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_pool_activs(model, cache:dict=None, c_type:str=None, I_range=None):\n",
    "    vals, names = localizing.collect_c_type(model=model, cache=cache, c_type=c_type)\n",
    "    pool_vals = localizing.pool_tensor(vals, pool=\"max\", abs_vals=True, topP=0.01, norm_by_entries=False)\n",
    "    \n",
    "    ## consider either all tokens or only selected token, then mean over sequences    \n",
    "    if I_range is not None: \n",
    "        pool_vals = pool_vals[:,I_range[0]:I_range[1]]\n",
    "    pool_vals = pool_vals.mean(1) ## pool over tokens\n",
    "    pool_vals = pool_vals.mean(0) ## pool over seqs\n",
    "            \n",
    "    ## reshape for plotting\n",
    "    names = list()\n",
    "    if len(pool_vals.shape) == 2: ## attention\n",
    "        names = [f\"{c_type} H{i}\" for i in range(0,pool_vals.shape[1])]\n",
    "    else: ## mlp\n",
    "        pool_vals = pool_vals.unsqueeze(-1)\n",
    "        names = [f\"{c_type}\"]\n",
    "    return pool_vals, names\n",
    "\n",
    "\n",
    "def gather_activation_grads(model, cache:dict, I_range:list=[50,100], c_types:list=[\"q\", \"k\", \"v\", \"z\", \"pre\", \"post\"]):  #\"q\", \"k\", \"v\", \"z\", \"pre\", \"post\", \"attn_out\", \"mlp_out\"\n",
    "    vals, names = [], []\n",
    "    for c_type in c_types:\n",
    "        c_type_vals, c_type_names = collect_pool_activs(model=model, cache=cache, c_type=c_type, I_range=I_range)\n",
    "        vals.append(c_type_vals)\n",
    "        names += c_type_names\n",
    "    vals = torch.cat(vals, dim=-1)\n",
    "    return vals, names\n",
    "\n",
    "\n",
    "def gather_param_grads(model, I_range:list=[50,100], c_types:list=[\"W_K\",\"W_Q\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]):\n",
    "    param_vals, param_names = [], []\n",
    "    for c_type in c_types:\n",
    "        vals, names = localizing.collect_c_type(model=model, cache=None, c_type=c_type) \n",
    "        if c_type in ['W_Q', 'W_K', 'W_V', 'W_O']: ## attention\n",
    "            vals = vals.view(vals.shape[0], vals.shape[1], -1)\n",
    "            names = [f\"{names[0].split('.')[-1]} H{i}\" for i in range(vals.shape[1])]\n",
    "        else: ## mlps\n",
    "            vals = vals.view(vals.shape[0], 1, -1)\n",
    "            names = [f\"{names[0].split('.')[-1]}\"]\n",
    "        pool_vals = localizing.pool_tensor(vals, pool=\"max\", abs_vals=True, topP=0.1, norm_by_entries=False)\n",
    "        param_vals.append(pool_vals)\n",
    "        param_names += names\n",
    "    param_vals = torch.cat(param_vals, dim=1)\n",
    "    return param_vals, param_names\n",
    "\n",
    "\n",
    "def gather_param_stats(model, param_stats, i, I_range:list=[49,99], c_types:list=[\"W_K\",\"W_Q\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]):\n",
    "    \n",
    "    param_stats[\"attn\"][i] = {l: 0.0 for l in range(model.cfg.n_layers)}\n",
    "    param_stats[\"mlp\"][i] = {l: 0.0 for l in range(model.cfg.n_layers)}\n",
    "\n",
    "    for c_type in c_types:\n",
    "        vals, names = localizing.collect_c_type(model=model, cache=None, c_type=c_type) \n",
    "        layer_sum = torch.reshape(torch.abs(vals), (model.cfg.n_layers,-1)).sum(-1)\n",
    "        param_stats[\"sum\"][i][c_type] = torch.abs(vals).sum().item()\n",
    "        #param_stats[\"mean\"][c_type] = vals.mean().item()\n",
    "        param_stats[\"var\"][i][c_type] = vals.var().item() \n",
    "        param_stats[\"max\"][i][c_type] = vals.max().item()\n",
    "        param_stats[\"min\"][i][c_type] = torch.abs(vals.min()).item()\n",
    "        \n",
    "        if c_type in [\"W_K\",\"W_V\",\"W_Q\",\"W_O\"]:\n",
    "            for l in range(model.cfg.n_layers):\n",
    "                param_stats[\"attn\"][i][l] += layer_sum[l].item()\n",
    "        elif c_type in [\"W_in\",\"W_out\"]:\n",
    "            for l in range(model.cfg.n_layers):\n",
    "                param_stats[\"mlp\"][i][l] += layer_sum[l].item()        \n",
    "        #stats = {\"abs_sum\": torch.abs(vals).sum().item(), \"mean\": vals.mean().item(), \"var\": vals.var().item(), \"max\": vals.max().item(), \"min\": torch.abs(vals.min()).item(), \"layer_abs_sum\":layer_sum}\n",
    "    return param_stats\n",
    "\n",
    "def gradient_stats(range_pool_vals:list):\n",
    "    total_grad = []\n",
    "    total_grad_per_layer = []\n",
    "    total_grad_var = []\n",
    "    for i, vals in enumerate(range_pool_vals):\n",
    "        total_grad.append(vals.sum())\n",
    "        grad_per_layer = [f\"{x:.2f}\" for x in vals.sum(-1)]\n",
    "        total_grad_per_layer.append(grad_per_layer)\n",
    "        total_grad_var.append(torch.var(vals).item())\n",
    "    return total_grad, total_grad_per_layer, total_grad_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b177f-4603-4dca-883b-fca522327799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fwd_bwd = \"bwd\"\n",
    "grad_type = \"params\"\n",
    "\n",
    "#I_range=[0,99]\n",
    "I_range=[49,99]\n",
    "\n",
    "range_pool_vals = []\n",
    "param_stats = {\"sum\": defaultdict(dict), \"var\": defaultdict(dict), \"max\": defaultdict(dict), \"min\": defaultdict(dict), \"attn\":defaultdict(dict), \"mlp\":defaultdict(dict)}\n",
    "\n",
    "for i, dl in tqdm.tqdm(enumerate(range_dl[:])):\n",
    "    toks_NI = next(iter(dl))\n",
    "    metric = functools.partial(gradient.single_seq_metric, NI_idcs=I_range)\n",
    "    fwd_cache, bwd_cache, _ = gradient.run_single_fwd_bwd(model, metric_fn=metric, c_toks_NI=toks_NI)\n",
    "    \n",
    "    ## POOL\n",
    "    if grad_type==\"activs\":\n",
    "        pool_vals, names = gather_activation_grads(model, {\"fwd\":fwd_cache,\"bwd\":bwd_cache}[fwd_bwd], I_range=I_range)\n",
    "    elif grad_type==\"params\":\n",
    "        pool_vals, names = gather_param_grads(model, I_range=I_range)\n",
    "        param_stats = gather_param_stats(model, param_stats, i, I_range=I_range)\n",
    "    range_pool_vals.append(pool_vals)\n",
    "    \n",
    "total_grad, total_grad_per_layer, total_grad_var = gradient_stats(range_pool_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1f145-7cd0-4a8a-97b2-421ac9dd557b",
   "metadata": {},
   "source": [
    "## Plot Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eecbda-23ee-4f45-9e82-0bdddf5f60ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fontsize = 12\n",
    "fig, axs = plt.subplots(len(range_pool_vals), 1, figsize=(16, 14), gridspec_kw={'hspace': 0.5})\n",
    "\n",
    "#plot_types = ['EM 0-10', 'EM 11-49', 'EM 50']\n",
    "plot_types = ['EM 0-10', 'EM 11-29', 'EM 30-49', 'EM 50']\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if i == 0:\n",
    "        cmap = \"Blues\"\n",
    "    elif i == 3:\n",
    "        cmap = \"Reds\"\n",
    "    else:\n",
    "        cmap = \"binary\"\n",
    "    \n",
    "    plot_vals = range_pool_vals[i].numpy()\n",
    "    #sns.heatmap(plot_vals[1:-1,:],cmap=mpl.colormaps[cmap],center=None,xticklabels=names,yticklabels=np.arange(1,plot_vals.shape[0]-1),square=False,ax=ax)# norm=SymLogNorm(linthresh=1.0))\n",
    "    sns.heatmap(plot_vals[:,:],cmap=mpl.colormaps[cmap],center=None,xticklabels=names,yticklabels=np.arange(0,plot_vals.shape[0]),square=False,ax=ax)#, norm=LogNorm())\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(f\"{plot_types[i]}: {fwd_bwd} {grad_type} grads for tokens {I_range[0]+1} to {I_range[1]+1} (grad sum: {total_grad[i]:.2f}, grad var: {total_grad_var[i]:.2e})\", fontsize=fontsize, loc=\"left\")\n",
    "    ax.set_ylabel(\"layer\", fontsize=fontsize)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=fontsize)\n",
    "    ax.tick_params(axis='x', which='major', labelsize=fontsize-3)\n",
    "\n",
    "    # Create a second y-axis on the right side\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_yticks(np.arange(0,len(total_grad_per_layer[i])))\n",
    "    ax2.set_yticklabels(total_grad_per_layer[i], fontsize = fontsize-4)\n",
    "    ax2.set_ylabel(\"layer-wise gradient sum\", fontsize = fontsize-4)\n",
    "    \n",
    "fig.savefig(f\"{dataLoaders.ROOT}/results/{model_type}_{grad_type}_max_{I_range[0]}_{I_range[1]}.pdf\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ec9dd-c439-49cc-b10a-86836a1ef5d8",
   "metadata": {},
   "source": [
    "## Plot Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416abe27-7072-4b87-83f0-e223c278340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 15\n",
    "fig, axs = plt.subplots(len(param_stats.keys()), 1, figsize=(16, 5.5), gridspec_kw={'hspace': 0.5})\n",
    "\n",
    "#plot_types = ['EM 0-10', 'EM 11-49', 'EM 50']\n",
    "plot_types = ['EM 0-10', 'EM 11-29', 'EM 30-49', 'EM 50']\n",
    "\n",
    "#cmap = plt.get_cmap('coolwarm')\n",
    "#cmap_discrete = ListedColormap(cmap(np.linspace(0, 1, len(x_labels)))).colors\n",
    "color = [\"blue\", \"grey\", \"grey\", \"red\"]\n",
    "bar_width, group_gap = 0.9, 0.5\n",
    "\n",
    "for i, (stat_name, range_param_dict) in enumerate(param_stats.items()):\n",
    "    \n",
    "    last_x = 0\n",
    "    row_x, row_labels = [], []\n",
    "    axs[i].tick_params(axis='both', which='major', labelsize=fontsize-4)\n",
    "    axs[i].set_ylabel(stat_name, rotation=90, fontsize=fontsize)\n",
    "    axs[i].yaxis.set_label_coords(-0.05, 0.5)\n",
    "    for j, (range_key, param_value_dict) in enumerate(range_param_dict.items()):\n",
    "        param_labels = list(param_value_dict.keys())\n",
    "        x = np.arange(0, len(param_labels)) + last_x   \n",
    "        row_x += list(x)\n",
    "        row_labels += param_labels\n",
    "        \n",
    "        y = list(param_value_dict.values())\n",
    "        axs[i].bar(x, y, bar_width, color=color[j])   \n",
    "        \n",
    "        if i==0: ## have x titles only in first row\n",
    "            axs[0].text(last_x, 4500, plot_types[j], fontsize=fontsize, color=color[j], verticalalignment='bottom')#, transform=axs[0].transAxes)\n",
    "        #if (i==1) or (i==2) or (i==3):\n",
    "        axs[i].set_yscale(\"log\")\n",
    "        \n",
    "        last_x += (len(x) + group_gap)\n",
    "    \n",
    "    axs[i].set_xlim(-1, row_x[-1]+1)\n",
    "    axs[i].set_xticks(row_x) \n",
    "    axs[i].set_xticklabels(row_labels, rotation=0, fontsize=fontsize-6)\n",
    "            \n",
    "fig.savefig(f\"{dataLoaders.ROOT}/results/{model_type}_{grad_type}_em_stats.pdf\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0da4f-97c5-4281-84e1-02752ebc9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mlp_stats = {k:v for k,v in param_stats.items() if k in ['attn', 'mlp']}\n",
    "\n",
    "fontsize = 15\n",
    "fig, axs = plt.subplots(len(attn_mlp_stats.keys()), 1, figsize=(16, 2), gridspec_kw={'hspace': 0.5})\n",
    "\n",
    "#plot_types = ['EM 0-10', 'EM 11-49', 'EM 50']\n",
    "plot_types = ['EM 0-10', 'EM 11-29', 'EM 30-49', 'EM 50']\n",
    "\n",
    "#cmap = plt.get_cmap('coolwarm')\n",
    "#cmap_discrete = ListedColormap(cmap(np.linspace(0, 1, len(x_labels)))).colors\n",
    "color = [\"blue\", \"grey\", \"grey\", \"red\"]\n",
    "bar_width, group_gap = 0.9, 0.5\n",
    "\n",
    "for i, (stat_name, range_param_dict) in enumerate(attn_mlp_stats.items()):\n",
    "    \n",
    "    last_x = 0\n",
    "    row_x, row_labels = [], []\n",
    "    axs[i].tick_params(axis='both', which='major', labelsize=fontsize-4)\n",
    "    axs[i].set_ylabel(stat_name, rotation=90, fontsize=fontsize)\n",
    "    axs[i].yaxis.set_label_coords(-0.05, 0.5)\n",
    "    for j, (range_key, param_value_dict) in enumerate(range_param_dict.items()):\n",
    "        param_labels = list(param_value_dict.keys())\n",
    "        x = np.arange(0, len(param_labels)) + last_x   \n",
    "        row_x += list(x)\n",
    "        row_labels += param_labels\n",
    "        \n",
    "        y = list(param_value_dict.values())\n",
    "        axs[i].bar(x, y, bar_width, color=color[j])   \n",
    "        \n",
    "        if i==0: ## have x titles only in first row\n",
    "            axs[0].text(last_x, 4500, plot_types[j], fontsize=fontsize, color=color[j], verticalalignment='bottom')#, transform=axs[0].transAxes)\n",
    "        #if (i==1) or (i==2) or (i==3):\n",
    "        axs[i].set_yscale(\"log\")\n",
    "        \n",
    "        last_x += (len(x) + group_gap)\n",
    "    \n",
    "    axs[i].set_xlim(-1, row_x[-1]+1)\n",
    "    axs[i].set_xticks(row_x) \n",
    "    axs[i].set_xticklabels(row_labels, rotation=0, fontsize=fontsize-6)\n",
    "            \n",
    "fig.savefig(f\"{dataLoaders.ROOT}/results/{grad_type}_em_stats.pdf\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e826e-ae03-43e3-91ff-3be192fa49d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

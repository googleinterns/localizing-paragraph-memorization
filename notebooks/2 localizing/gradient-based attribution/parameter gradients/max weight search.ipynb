{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e6c391",
   "metadata": {},
   "source": [
    "\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-2qpyRvJYRR"
   },
   "source": [
    "# Max Weight Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6686,
     "status": "ok",
     "timestamp": 1702663207018,
     "user": {
      "displayName": "Niklas Stoehr",
      "userId": "03296628557932703282"
     },
     "user_tz": 480
    },
    "id": "UBSfNkEuJMGQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import transformer_lens\n",
    "import torch, gc, itertools, tqdm, scipy, functools, collections, copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import localizing, modelHandlers, dataLoaders, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nn9H9zcaN4Hg"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6203,
     "status": "ok",
     "timestamp": 1702663213774,
     "user": {
      "displayName": "Niklas Stoehr",
      "userId": "03296628557932703282"
     },
     "user_tz": 480
    },
    "id": "QpqHz8RkJTix",
    "outputId": "7d76e1f4-ed39-4c65-b30f-e55d8075b9d5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"gpt-neo-125M\"\n",
    "model = modelHandlers.load_model(model_type=model_type, DEVICE=\"cpu\")\n",
    "modelHandlers.set_no_grad(model, [\"embed\", \"pos_embed\", \"unembed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYuz0oTRvDPu"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1339,
     "status": "ok",
     "timestamp": 1702663215109,
     "user": {
      "displayName": "Niklas Stoehr",
      "userId": "03296628557932703282"
     },
     "user_tz": 480
    },
    "id": "AIHeyTY1Sj3U",
    "outputId": "87916eaf-59a3-4424-92a8-00b5b73ee87c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl, test_dl = dataLoaders.batched_pile(mem_batch=5, non_mem_batch=10, test_frac=0.0)\n",
    "#dl = dataLoaders.batched_pop_seqs(model, mem_batch=5, non_mem_batch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batched_c_type_collection(model, dl, run_fwd_bwd, c_types:list=[\"W_Q\",\"W_K\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"], n_batches:int=10, norm_by_batch:bool=True):\n",
    "    \"\"\"\n",
    "    summing all gradient weights in component c_type over multiple batches\n",
    "    \"\"\"\n",
    "    weight_gradients = collections.defaultdict(torch.tensor)\n",
    "    for batch_i, (c_toks_NI, k_toks_NI) in tqdm.tqdm(enumerate(dl)):\n",
    "        fwd_cache, bwd_cache = run_fwd_bwd(model, c_toks_NI.squeeze(0), k_toks_NI.squeeze(0))\n",
    "        for c_type in c_types:\n",
    "            if c_type in [\"W_Q\",\"W_K\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]: ## model params\n",
    "                c_vals, c_names = localizing.collect_c_type(model=model, cache=None, c_type=c_type)\n",
    "            elif c_type in [\"q\",\"k\",\"v\",\"o\",\"mlp_in\",\"mlp_out\"]: ## activation\n",
    "                c_vals, c_names = localizing.collect_c_type(model=model, cache=bwd_cache, c_type=c_type)\n",
    "            else:\n",
    "                raise Exception(f\"No eligible parameter oder activation name passed: {c_types}\")\n",
    "                \n",
    "            ## Summing up values___________________________\n",
    "            c_vals = c_vals.detach() \n",
    "            if norm_by_batch:\n",
    "                c_vals = c_vals / n_batches\n",
    "            if batch_i == 0:\n",
    "                weight_gradients[c_type] = c_vals \n",
    "            else:\n",
    "                weight_gradients[c_type] += c_vals \n",
    "        if batch_i+1 == n_batches: ## break early\n",
    "            return weight_gradients\n",
    "    return weight_gradients\n",
    " \n",
    "c_types=[\"W_in\", \"W_out\", \"W_Q\", \"W_K\", \"W_V\", \"W_O\"]\n",
    "fwd_bwd = functools.partial(gradient.run_fwd_bwd, after_I=0, with_mse=True,pool={\"c\":[-1],\"k\":[0,-1]})\n",
    "c_grads = batched_c_type_collection(model, train_dl, fwd_bwd, c_types=c_types, n_batches=2)\n",
    "localizing.store_data(c_grads, f\"results/{model_type}/{'_'.join(c_types)}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_topK_grads(c_grads:dict, topK:int=100, select_c:list=None, select_l:list=None, select_heads:list=[], return_lk:bool=False, largest:bool=True, select_random:bool=False):\n",
    "    \"\"\"\n",
    "    weight_gradients is a list of tensors, collect topK weight gradients and return as layer-wise list and in original shape\n",
    "    \"\"\"\n",
    "    c_grads = copy.deepcopy(c_grads)\n",
    "    ## (1) prepare components and layers\n",
    "    n_layers = list(c_grads.values())[0].shape[0]\n",
    "    if select_l is None or len(select_l) == 0:\n",
    "        select_l = list(range(n_layers))\n",
    "    remove_layers = list(range(n_layers))\n",
    "    remove_layers = list(set(remove_layers).difference(set(select_l)))\n",
    "    if select_c is None or len(select_c) == 0:\n",
    "        select_c = list(c_grads.keys())\n",
    "        \n",
    "    ## (2) gather the top gradients\n",
    "    c_top_grads = {}\n",
    "    for c_type,c_vals in c_grads.items():\n",
    "        if c_type in select_c:\n",
    "            if len(select_heads) > 0 and len(c_vals.shape) >= 4: ##select specific head from attention component \n",
    "                c_vals = c_vals[:,torch.LongTensor(select_heads),:,:]\n",
    "            gradients_ld = c_vals.view(c_vals.shape[0],-1) ## flatten tensor to l_dim and model_dim\n",
    "            gradients_ld[torch.LongTensor(remove_layers),:] = gradients_ld[torch.LongTensor(remove_layers),:]*0 ## filter layers based on select_layers criterion  \n",
    "            if select_random==False: ## normal topK selection mode\n",
    "                weight_scores, weight_idcs = torch.topk(gradients_ld.flatten(), topK, largest=largest)\n",
    "            else: ## selecting any random weights as a baseline\n",
    "                random_idcs = torch.randperm(gradients_ld.flatten().shape[0])\n",
    "                weight_scores, weight_idcs = gradients_ld.flatten()[random_idcs[:topK]], random_idcs[:topK].squeeze()\n",
    "            weight_idcs = torch.tensor(np.array(np.unravel_index(weight_idcs.numpy(), gradients_ld.shape))).T\n",
    "            c_top_grads[c_type]={\"idcs\": weight_idcs, \"scores\": weight_scores}\n",
    "\n",
    "            if return_lk: ## reformat the output to return layer-wise list of lists\n",
    "                weight_ids_lk = [[] for l in range(n_layers)]\n",
    "                weight_scores_lk = [[] for l in range(n_layers)]\n",
    "                for k, weight_idx in enumerate(weight_idcs):\n",
    "                    weight_ids_lk[weight_idx[0]].append(weight_idx[1].item())\n",
    "                    weight_scores_lk[weight_idx[0]].append(weight_scores[k].item())\n",
    "                c_top_grads[c_type]={\"idcs\": weight_ids_lk, \"scores\": weight_scores_lk}\n",
    "    return c_top_grads\n",
    "\n",
    "c_top_grads = get_topK_grads(c_grads, topK=100, select_c=[\"W_Q\",\"W_V\"], select_l=[2], select_heads=[11], return_lk=False, largest=True, select_random=False)\n",
    "c_top_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_max_gradients(c_top_grads:dict, topK:int=None, n_layers:int=11):\n",
    "    \"\"\"\n",
    "    plotting the max gradients in model component and coloring by layer index\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(len(c_top_grads.keys()), 1, figsize=(10, 4), gridspec_kw={'hspace': 0.1, 'wspace': 0.05}, constrained_layout=True)\n",
    "    fontsize=10\n",
    "    \n",
    "    cmap = plt.cm.Blues\n",
    "    norm = mpl.colors.Normalize(0, n_layers)\n",
    "\n",
    "    for i, (c_type, idcs_scores) in enumerate(c_top_grads.items()):\n",
    "        scores = c_top_grads[c_type][\"scores\"][:topK]\n",
    "        layers = c_top_grads[c_type][\"idcs\"][:,0][:topK]\n",
    "        colors = cmap(norm(layers))\n",
    "        \n",
    "        bars = axs[i].bar(np.arange(0,len(scores)),scores, color=colors)\n",
    "        axs[i].axhline(y=scores.mean(), color='r', linewidth=1, linestyle='--', c=\"black\", alpha=0.5)\n",
    "        \n",
    "        axs[i].set_title(f\"Max weight gradients of parameter {c_type}\", loc=\"left\", fontsize=fontsize+2)\n",
    "        axs[i].set_ylabel('gradient value', color='black', fontsize=fontsize)\n",
    "        if i == len(c_top_grads.keys())-1:\n",
    "            axs[i].set_xlabel('topK weights', color='black', fontsize=fontsize)\n",
    "        axs[i].set_xlim(-1, len(scores))\n",
    "        \n",
    "        scalarmappaple = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "        scalarmappaple.set_array(layers.tolist())\n",
    "        plt.colorbar(scalarmappaple, ax=axs[i], label=\"model layer\", pad=-0.0)\n",
    "\n",
    "\n",
    "plot_max_gradients(c_top_grads, n_layers=model.cfg.n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGB+zTCDBCeQ63kuW0ZbKy",
   "mount_file_id": "1gH7CY-pBqILLrkbypyW6G3qurtUUqqwl",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ac11ae",
   "metadata": {},
   "source": [
    "\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeacd3b-9676-4786-b485-66e016c9cb82",
   "metadata": {},
   "source": [
    "# Contrastive Grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3b83b-4985-4bcb-ae2c-78cd8d023e69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import transformer_lens, torch, gc, itertools, functools, math, glob, tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LogNorm, SymLogNorm\n",
    "\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.bottom'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import modelHandlers, dataLoaders, gradient, localizing, patching\n",
    "\n",
    "torch.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8439948d-afb3-472f-8dde-c0ea88b5b4df",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32953121-1ca8-40ff-96eb-63b822bdfe9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"gpt-neo-125M\"\n",
    "model = modelHandlers.load_model(model_type=model_type, DEVICE=\"cpu\")\n",
    "modelHandlers.set_no_grad(model, [\"embed\", \"pos_embed\", \"unembed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30427e33-f8b3-422e-9768-9180d7f3749e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30435018-6690-478c-b559-8dbf80b03908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mem_nonmem_sets  = dataLoaders.load_pile_splits(f\"{model_type}/preds\", file_names=[\"50_50_preds.pt\", \"0_10_preds.pt\"], as_torch=True)\n",
    "mem_set, non_mem_set = mem_nonmem_sets[0], mem_nonmem_sets[1]\n",
    "train_dl, test_dl = dataLoaders.train_test_batching(mem_set, non_mem_set, mem_batch=30, non_mem_batch=30, test_frac=0.2, shuffle=True, add_bos=None)\n",
    "c_toks_NI, k_toks_NI = next(iter(train_dl))\n",
    "c_toks_NI, k_toks_NI = c_toks_NI.squeeze(0), k_toks_NI.squeeze(0)\n",
    "\n",
    "## load perturbed mem set and original mem set\n",
    "mem_perturbed_sets  = dataLoaders.load_pile_splits(f\"{model_type}/perturbed\", file_names=[\"mem_toks.pt\", \"perturbed_mem_toks.pt\"], as_torch=True)\n",
    "mem_set, perturbed_mem_set = mem_perturbed_sets[0], mem_perturbed_sets[1]\n",
    "train_dl, test_dl = dataLoaders.train_test_batching(mem_set, perturbed_mem_set, mem_batch=30, non_mem_batch=30, test_frac=0.2, shuffle=True, add_bos=None)\n",
    "c_toks_NI, c_perturb_toks_NI = next(iter(train_dl))\n",
    "c_toks_NI, c_perturb_toks_NI, = c_toks_NI.squeeze(0), c_perturb_toks_NI.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc151634-f609-4cf1-b10b-9cff0d2a8ed7",
   "metadata": {},
   "source": [
    "### Run backprop and gather gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3e352-d2d6-453d-b4d2-d1cb38ded27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_pool_activs(model, cache:dict=None, c_type:str=None, I_range=None):\n",
    "    vals, names = localizing.collect_c_type(model=model, cache=cache, c_type=c_type)\n",
    "    pool_vals = localizing.pool_tensor(vals, pool=\"max\", abs_vals=True, topP=0.01, norm_by_entries=False)\n",
    "    \n",
    "    ## consider either all tokens or only selected token, then mean over sequences    \n",
    "    if I_range is not None: \n",
    "        pool_vals = pool_vals[:,I_range[0]:I_range[1]]\n",
    "    pool_vals = pool_vals.mean(1) ## pool over tokens\n",
    "    pool_vals = pool_vals.mean(0) ## pool over seqs\n",
    "            \n",
    "    ## reshape for plotting\n",
    "    names = list()\n",
    "    if len(pool_vals.shape) == 2: ## attention\n",
    "        names = [f\"{c_type} H{i}\" for i in range(0,pool_vals.shape[1])]\n",
    "    else: ## mlp\n",
    "        pool_vals = pool_vals.unsqueeze(-1)\n",
    "        names = [f\"{c_type}\"]\n",
    "    return pool_vals, names\n",
    "\n",
    "\n",
    "def gather_activation_grads(model, cache:dict, I_range:list=[50,100], c_types:list=[\"q\", \"k\", \"v\", \"z\", \"pre\", \"post\"]):  #\"q\", \"k\", \"v\", \"z\", \"pre\", \"post\", \"attn_out\", \"mlp_out\"\n",
    "    vals, names = [], []\n",
    "    for c_type in c_types:\n",
    "        c_type_vals, c_type_names = collect_pool_activs(model=model, cache=cache, c_type=c_type, I_range=I_range)\n",
    "        vals.append(c_type_vals)\n",
    "        names += c_type_names\n",
    "    vals = torch.cat(vals, dim=-1)\n",
    "    return vals, names\n",
    "\n",
    "\n",
    "def gather_param_grads(model, I_range:list=[50,100], c_types:list=[\"W_K\",\"W_Q\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]):\n",
    "    param_vals, param_names = [], []\n",
    "    for c_type in c_types:\n",
    "        vals, names = localizing.collect_c_type(model=model, cache=None, c_type=c_type) \n",
    "        if c_type in ['W_Q', 'W_K', 'W_V', 'W_O']: ## attention\n",
    "            vals = vals.view(vals.shape[0], vals.shape[1], -1)\n",
    "            names = [f\"{names[0].split('.')[-1]} H{i}\" for i in range(vals.shape[1])]\n",
    "        else: ## mlps\n",
    "            vals = vals.view(vals.shape[0], 1, -1)\n",
    "            names = [f\"{names[0].split('.')[-1]}\"]\n",
    "        pool_vals = localizing.pool_tensor(vals, pool=\"max\", abs_vals=True, topP=0.1, norm_by_entries=False)\n",
    "        param_vals.append(pool_vals)\n",
    "        param_names += names\n",
    "    param_vals = torch.cat(param_vals, dim=1)\n",
    "    return param_vals, param_names\n",
    "\n",
    "\n",
    "def gather_param_stats(model, param_stats, I_range:list=[49,99], c_types:list=[\"W_K\",\"W_Q\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]):\n",
    "    \n",
    "    param_stats[\"attn\"] = {l: 0.0 for l in range(model.cfg.n_layers)}\n",
    "    param_stats[\"mlp\"] = {l: 0.0 for l in range(model.cfg.n_layers)}\n",
    "\n",
    "    for c_type in c_types:\n",
    "        vals, names = localizing.collect_c_type(model=model, cache=None, c_type=c_type) \n",
    "        layer_sum = torch.reshape(torch.abs(vals), (model.cfg.n_layers,-1)).sum(-1)\n",
    "        param_stats[\"sum\"][c_type] = torch.abs(vals).sum().item()\n",
    "        #param_stats[\"mean\"][c_type] = vals.mean().item()\n",
    "        param_stats[\"var\"][c_type] = vals.var().item() \n",
    "        param_stats[\"max\"][c_type] = vals.max().item()\n",
    "        param_stats[\"min\"][c_type] = torch.abs(vals.min()).item()\n",
    "        \n",
    "        if c_type in [\"W_K\",\"W_V\",\"W_Q\",\"W_O\"]:\n",
    "            for l in range(model.cfg.n_layers):\n",
    "                param_stats[\"attn\"][l] += layer_sum[l].item()\n",
    "        elif c_type in [\"W_in\",\"W_out\"]:\n",
    "            for l in range(model.cfg.n_layers):\n",
    "                param_stats[\"mlp\"][l] += layer_sum[l].item()        \n",
    "        #stats = {\"abs_sum\": torch.abs(vals).sum().item(), \"mean\": vals.mean().item(), \"var\": vals.var().item(), \"max\": vals.max().item(), \"min\": torch.abs(vals.min()).item(), \"layer_abs_sum\":layer_sum}\n",
    "    return param_stats\n",
    "\n",
    "def gradient_stats(pool_vals:list):\n",
    "    total_grad = pool_vals.sum()\n",
    "    total_grad_per_layer = [f\"{x:.2f}\" for x in pool_vals.sum(-1)]\n",
    "    total_grad_var = torch.var(pool_vals).item()\n",
    "    return total_grad, total_grad_per_layer, total_grad_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b177f-4603-4dca-883b-fca522327799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = modelHandlers.load_model(model, lr=1e-05, weight_decay=1.0)\n",
    "metric_fn = functools.partial(gradient.contrast_metric, I_range=[49,99], use_perturb=False, c_set_norm=0.1)\n",
    "fwd_bwd_fn = functools.partial(gradient.run_contrastive_fwd_bwd, optim_steps=-1, topK=None, grad_norm=None, c_types=[\"W_V\",\"W_Q\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]) \n",
    "fwd_cache, bwd_cache, topk_idcs = fwd_bwd_fn(model, metric_fn, c_toks_NI, c_perturb_toks_NI, k_toks_NI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca7987-ceea-43bb-8c4d-bae6461a8cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fwd_bwd = \"bwd\"\n",
    "grad_type = \"params\"\n",
    "\n",
    "#I_range=[0,99]\n",
    "I_range=[49,99]\n",
    "\n",
    "param_stats = {\"sum\": defaultdict(dict), \"var\": defaultdict(dict), \"max\": defaultdict(dict), \"min\": defaultdict(dict), \"attn\":defaultdict(dict), \"mlp\":defaultdict(dict)}\n",
    "\n",
    "## POOL\n",
    "if grad_type==\"activs\":\n",
    "    pool_vals, names = gather_activation_grads(model, {\"fwd\":fwd_cache,\"bwd\":bwd_cache}[fwd_bwd], I_range=I_range)\n",
    "elif grad_type==\"params\":\n",
    "    pool_vals, names = gather_param_grads(model, I_range=I_range)\n",
    "    param_stats = gather_param_stats(model, param_stats, I_range=I_range)\n",
    "\n",
    "total_grad, total_grad_per_layer, total_grad_var = gradient_stats(pool_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1f145-7cd0-4a8a-97b2-421ac9dd557b",
   "metadata": {},
   "source": [
    "## Plot Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00719d21-d668-44ed-b548-03bf3a5980a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fontsize = 12\n",
    "fig, ax = plt.subplots(1, 1, figsize=(17, 3), gridspec_kw={'hspace': 0.5})\n",
    "\n",
    "plot_vals = pool_vals.numpy()\n",
    "s = sns.heatmap(plot_vals[:,:],cmap=\"binary\",center=None,xticklabels=names,yticklabels=np.arange(0,plot_vals.shape[0]),square=False,ax=ax, cbar_kws={'location': 'right','pad': 0.05})#, norm=LogNorm())\n",
    "s.set_yticklabels(s.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.set_title(f\"Parameter gradients for contrastive objective on tokens {I_range[0]+1} to {I_range[1]+1}\", fontsize=fontsize, loc=\"left\")\n",
    "ax.tick_params(axis='y', which='major', labelsize=fontsize)\n",
    "ax.tick_params(axis='x', which='major', labelsize=fontsize-3)\n",
    "ax.set_ylabel(\"layer\", fontsize=fontsize)\n",
    "\n",
    "# Create a second y-axis on the right side\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_yticks(np.arange(0,len(total_grad_per_layer)))\n",
    "ax2.set_yticklabels(total_grad_per_layer, fontsize = fontsize-2)\n",
    "ax2.set_ylabel(\"layer-wise gradient sum\", fontsize = fontsize-2)\n",
    "\n",
    "fig.savefig(f\"{dataLoaders.ROOT}/results/contrastive_objective_max_{I_range[0]}_{I_range[1]}.pdf\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0da4f-97c5-4281-84e1-02752ebc9818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf50106-0ee5-407c-a4fc-120ea1dcf00e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

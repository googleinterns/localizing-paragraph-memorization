{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7f8ba94",
   "metadata": {},
   "source": [
    "\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d70f2e-2d26-4b1e-9904-221277fc9883",
   "metadata": {
    "id": "59d70f2e-2d26-4b1e-9904-221277fc9883"
   },
   "source": [
    "# Post-Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385a2b45-0a48-4ec4-b231-b54bd9ffbecc",
   "metadata": {
    "id": "385a2b45-0a48-4ec4-b231-b54bd9ffbecc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gb total: 15.6535, reserved: 0.0, allocated: 0.0\n"
     ]
    }
   ],
   "source": [
    "#@title Import libraries\n",
    "import transformer_lens\n",
    "import torch, gc, itertools, tqdm, scipy, copy, functools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import modelHandlers, dataLoaders, gradient, intervening, localizing\n",
    "modelHandlers.gpu_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73414b4-289e-4b9e-afe2-80af0af1ee40",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68924f4c-abd1-4f40-a659-36d67d71e064",
   "metadata": {
    "id": "68924f4c-abd1-4f40-a659-36d67d71e064",
    "outputId": "856915ea-112a-49d7-95ec-eac0b12c730f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt-neo-125M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_type = \"gpt-neo-125M\"\n",
    "model = modelHandlers.load_model(model_type=model_type, DEVICE=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5fff3-11da-4435-a593-3aab22abe1c9",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19b28205-2803-49dc-867e-1a0380dc0e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl, test_dl = dataLoaders.batched_pile(mem_batch=5, non_mem_batch=10, test_frac=0.0, shuffle=False)\n",
    "#dl = dataLoaders.batched_pop_seqs(model, mem_batch=5, non_mem_batch=10)\n",
    "c_toks_NI, k_toks_NI = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab85c86-7319-4354-9250-874a1ca7b378",
   "metadata": {},
   "source": [
    "### Obtain or Load Intervention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "061e3000-83c7-4f5d-8253-65d9cbe79a13",
   "metadata": {
    "id": "061e3000-83c7-4f5d-8253-65d9cbe79a13",
    "outputId": "a24c4572-f7f4-42b3-a56e-e3ce62cbcc67",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrast_res: 0.6557825803756714, c_nll: 0.6557825803756714, k_nll: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:05, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returning ['blocks.0.attn.W_Q', 'blocks.1.attn.W_Q']... of shape: torch.Size([12, 12, 768, 64])\n",
      "returning ['blocks.0.attn.W_K', 'blocks.1.attn.W_K']... of shape: torch.Size([12, 12, 768, 64])\n",
      "returning ['blocks.0.attn.W_V', 'blocks.1.attn.W_V']... of shape: torch.Size([12, 12, 768, 64])\n",
      "returning ['blocks.0.attn.W_O', 'blocks.1.attn.W_O']... of shape: torch.Size([12, 12, 64, 768])\n",
      "returning ['blocks.0.mlp.W_in', 'blocks.1.mlp.W_in']... of shape: torch.Size([12, 768, 3072])\n",
      "returning ['blocks.0.mlp.W_out', 'blocks.1.mlp.W_out']... of shape: torch.Size([12, 3072, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c_types= [\"W_Q\",\"W_K\",\"W_V\",\"W_O\",\"W_in\",\"W_out\"]\n",
    "fwd_bwd = functools.partial(gradient.run_fwd_bwd, after_I=0, with_mse=True, pool={\"c\":[-1],\"k\":[0,-1]}, norm_sets=False)\n",
    "c_weights = localizing.batched_c_type_collection(model, train_dl, fwd_bwd, c_types=c_types, n_batches=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c1a6f-7e72-48f7-80de-f6886a0b891d",
   "metadata": {},
   "source": [
    "### Collect continuations on keep set before making any model interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b54f4b6-c702-48d4-8dc5-1d9c80338491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f84c9fbeaf4c22b2858de487a881fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[', and/or other securities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities',\n",
       " '}\\n                                                ',\n",
       " ' for the purpose of this application. Please note that the reserved words are not to be used in any other application. **\"\\n            },\\n           ',\n",
       " 'alt.interwalt.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:141)\\nat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235)\\n',\n",
       " ' public:\\n    S6(int v) : a(v) {}\\n    S6(int v) : a(v) {}\\n    S6(int v) : a(v) {}',\n",
       " '1-2).\\n\\nThe song is a reference to the song of the young man who is the father of the son who is the father of the son who is the father of the son who is the father of the son who is the father',\n",
       " 'ofday|timeofyear)(\\\\.)?(\\\\/\\\\.(\\\\d{1,3}|\\\\d{1,3}|\\\\d{1,3}|\\\\d{1,3}|\\\\d{1',\n",
       " ' customer service, we&rsquo;ll be happy to help you.\\n\\nWe&rsquo;re proud of our customers&rsquo;s ability to make a difference in the world. We&rsquo;',\n",
       " ' was the only way to get him to do it.\\n\\nHe was the boss\"s man spineless, and with no understanding. What about if he reported sick? But that was the only way to get him to do it.\\n\\n',\n",
       " 'Tag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_decode(model, toks_NI:torch.LongTensor=None, dl=None, n_batch:int=50, start_at_tok:int=50, new_toks:int=50, do_sample:bool=False):\n",
    "    \"\"\"\n",
    "    generate new toks from a model given a prompt\n",
    "    \"\"\"\n",
    "    if dl is None:\n",
    "        dl = zip(toks_NI, toks_NI)\n",
    "    preds_NI, trues_NI = [],[]\n",
    "    for batch_i, (_, k_toks_NI) in tqdm.tqdm(enumerate(dl)):\n",
    "        toks_NI = k_toks_NI.detach().to(model.cfg.device).squeeze(0) ## detach and put on device\n",
    "        toks_NI_pref, toks_NI_true = toks_NI[...,:start_at_tok], toks_NI[...,-start_at_tok:]\n",
    "        toks_NI_pred = model.generate(input=toks_NI_pref, max_new_tokens=new_toks, stop_at_eos=True, eos_token_id=None, do_sample=do_sample, top_k=None, top_p=None, temperature=1.0)\n",
    "        toks_NI_pred = toks_NI_pred[...,-new_toks:] ## only take continuations  \n",
    "        preds_NI.append(toks_NI_pred)\n",
    "        trues_NI.append(toks_NI_true)\n",
    "        \n",
    "        if batch_i+1 == n_batch:\n",
    "            break ## break early if too many items in dl\n",
    "    preds_NI = torch.stack(preds_NI).view(-1,new_toks)\n",
    "    trues_NI = torch.stack(trues_NI).view(-1,new_toks)\n",
    "    return preds_NI, trues_NI\n",
    "\n",
    "k_preds_orig, _ = batch_decode(model, toks_NI=None, dl=train_dl, n_batch=1)\n",
    "model.to_string(k_preds_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81edd74e-4fec-4924-84e4-72643289273e",
   "metadata": {},
   "source": [
    "### Make Model Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dadd68a0-7e37-4bcb-8a68-3605dffca091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 12, 768, 64])\n",
      "Loaded pretrained model gpt-neo-125M into HookedTransformer\n",
      "intervened with 0.01 on a total of 10 weights in ['W_V'] in layers {2}\n"
     ]
    }
   ],
   "source": [
    "topK, select_c, select_l, select_heads, intervene_val = 10, [\"W_V\"], [2], [11], 0.01\n",
    "c_weights_lk = intervening.get_topK_grads(c_weights,topK=topK,select_c=select_c,select_l=select_l,select_heads=select_heads,return_lk=True,largest=True,select_random=False)\n",
    "model = intervening.intervene_params(model, c_weights_lk, set_val=intervene_val, as_noise=True, set_type=\"add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a89bebb5-e7ee-4148-b6ed-4839de4def03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b137ff3c5a524b8cbfe06e9b3026bdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match between original and intervened continuation of keep set: 26.299999237060547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[', and/or other securities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities and/or commodities',\n",
       " '}\\n                                                ',\n",
       " ' for the purpose of this application. Please note that the reserved words are not to be used in any other application. **\"\\n            },\\n           ',\n",
       " 'alt.interwalt.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:141)\\nat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235)\\n',\n",
       " ' public:\\n    S6(int v) : a(v) {}\\n    S6(int v) : a(v) {}\\n    S6(int v) : a(v) {}',\n",
       " '1-2).\\n\\nThe song is a reference to the song of the young man who is the father of the son who is the father of the son who is the father of the son who is the father of the son who is the father',\n",
       " 'ofday|timeofyear)(\\\\.)?(\\\\/\\\\.(\\\\d{1,3}|\\\\d{1,3}|\\\\d{1,3}|\\\\d{1,3}|\\\\d{1',\n",
       " ' customer service, we&rsquo;ll be happy to help you.\\n\\nWe&rsquo;re proud of our customers&rsquo;s ability to make a difference in the world. We&rsquo;',\n",
       " ' was the only way to get him to do it.\\n\\nHe was the boss\"s man spineless, and with no understanding. What about if he reported sick? But that was the only way to get him to do it.\\n\\n',\n",
       " 'Tag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag\\n\\nAttribute:LanguageAndTag']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_pred_intervened, _ = batch_decode(model, toks_NI=None, dl=train_dl, n_batch=1)\n",
    "orig_interv_em = modelHandlers.compute_exact_match(k_pred_intervened, k_preds_orig)\n",
    "print(f\"Exact match between original and intervened continuation of keep set: {orig_interv_em.float().mean().item()}\")\n",
    "#ck_em, ck_nll = intervening.evaluate_model(model, dl=train_dl)\n",
    "model.to_string(preds_NI_intervened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491004e1-fd58-49df-b551-da972e01664e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

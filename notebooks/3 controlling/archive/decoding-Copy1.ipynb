{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d70f2e-2d26-4b1e-9904-221277fc9883",
   "metadata": {
    "id": "59d70f2e-2d26-4b1e-9904-221277fc9883"
   },
   "source": [
    "# LM Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385a2b45-0a48-4ec4-b231-b54bd9ffbecc",
   "metadata": {
    "id": "385a2b45-0a48-4ec4-b231-b54bd9ffbecc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import transformer_lens\n",
    "import torch, gc, itertools, tqdm, scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import helpers, modelHandlers, dataLoaders, decoding, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68924f4c-abd1-4f40-a659-36d67d71e064",
   "metadata": {
    "id": "68924f4c-abd1-4f40-a659-36d67d71e064",
    "outputId": "856915ea-112a-49d7-95ec-eac0b12c730f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt-neo-125M into HookedTransformer\n",
      "set no_grad on ['embed', 'pos_embed', 'unembed']\n"
     ]
    }
   ],
   "source": [
    "model = modelHandlers.load_model(model_type=\"gpt-neo-125M\", DEVICE=\"cpu\")\n",
    "modelHandlers.set_no_grad(model, [\"embed\", \"pos_embed\", \"unembed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e3000-83c7-4f5d-8253-65d9cbe79a13",
   "metadata": {
    "id": "061e3000-83c7-4f5d-8253-65d9cbe79a13",
    "outputId": "a24c4572-f7f4-42b3-a56e-e3ce62cbcc67"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479886ddaaf44c98b6cd1a1e048c4a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"An apple a day keeps the doctor away.\\n\\nThat's the\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(input=\"An apple a day\", max_new_tokens=10, stop_at_eos=True, eos_token_id=None, do_sample=False, top_k=None, top_p=None, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da2115-ad0f-4dd3-a99a-cfbbfdb3d85e",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "068a3bb073eb4589bcb3f028296fba93"
     ]
    },
    "id": "07da2115-ad0f-4dd3-a99a-cfbbfdb3d85e",
    "outputId": "818b7566-7614-4c05-92dc-effa861a231a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068a3bb073eb4589bcb3f028296fba93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Jeff Dean was born on March 24, 1982 in Oranda, Kansas,'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(input=\"Jeff Dean was born on\", max_new_tokens=10, stop_at_eos=True, eos_token_id=None, do_sample=True, top_k=None, top_p=None, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac63e4-0171-4d49-8ebb-8727bea7b741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(model, toks_NI:\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mLongTensor, new_toks:\u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size:\u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, stop_at_eos:\u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     toks_NI \u001b[38;5;241m=\u001b[39m toks_NI\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;66;03m## detach and put on device\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     preds_NI, trues_NI \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(toks_NI\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], new_toks), torch\u001b[38;5;241m.\u001b[39mLongTensor(toks_NI\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], new_toks)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def batch_decode(model, toks_NI:torch.LongTensor, new_toks:int=50, batch_size:int=5, stop_at_eos:bool=True):\n",
    "    toks_NI = toks_NI.detach().to(model.cfg.device) ## detach and put on device\n",
    "    preds_NI, trues_NI = torch.LongTensor(toks_NI.shape[0], new_toks), torch.LongTensor(toks_NI.shape[0], new_toks)\n",
    "    \n",
    "    toks_BNI = torch.split(toks_NI.detach(), batch_size) ## split in batches\n",
    "    for b, toks_NI in tqdm.tqdm(enumerate(toks_BNI)):\n",
    "        toks_NI_pref, toks_NI_true = toks_NI.detach()[...,:-new_toks], toks_NI.detach()[...,-new_toks:]\n",
    "        toks_NI_pred = model.generate(input=toks_NI_pref, max_new_tokens=new_toks, stop_at_eos=stop_at_eos, eos_token_id=None, do_sample=False, top_k=None, top_p=None, temperature=1.0)\n",
    "        toks_NI_pred = toks_NI_pred[...,-new_toks:] ## only take continuations  \n",
    "        \n",
    "        N = toks_NI.shape[0]\n",
    "        current_B = toks_NI.shape[0]\n",
    "        preds_NI[b*batch_size:(b*batch_size)+current_B,:] = toks_NI_pred\n",
    "        trues_NI[b*batch_size:(b*batch_size)+current_B,:] = toks_NI_true\n",
    "        del toks_NI_pred\n",
    "    del toks_NI\n",
    "    return preds_NI, trues_NI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f737f76e-3686-4f9a-a4a0-33c944f4e1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

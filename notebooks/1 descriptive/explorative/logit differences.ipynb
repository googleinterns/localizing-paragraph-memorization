{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf62b0e",
   "metadata": {},
   "source": [
    "\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6141b7-8581-4ae5-85e2-39b4669e4ac0",
   "metadata": {
    "id": "6f6141b7-8581-4ae5-85e2-39b4669e4ac0"
   },
   "source": [
    "# Logit Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a387aa-48fa-41b1-a39e-bee89cc1c262",
   "metadata": {
    "id": "10a387aa-48fa-41b1-a39e-bee89cc1c262"
   },
   "source": [
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6064bd-41a0-421c-9793-5b9c910efe38",
   "metadata": {
    "id": "2b6064bd-41a0-421c-9793-5b9c910efe38",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, MaxNLocator\n",
    "\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import helpers, model_loaders, data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df482c66-f797-4b1e-9417-a894b5bf2672",
   "metadata": {
    "id": "df482c66-f797-4b1e-9417-a894b5bf2672",
    "outputId": "c6f400e9-4ed5-4197-f399-9e910033ca0c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model_loaders.load_model(model_type=\"gpt2-xl\", DEVICE=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5873f60-7080-47dd-adfb-ffc17bb49070",
   "metadata": {
    "id": "b5873f60-7080-47dd-adfb-ffc17bb49070"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffec2d-1f80-411b-a8c8-36f405cbb63c",
   "metadata": {
    "id": "00ffec2d-1f80-411b-a8c8-36f405cbb63c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_scores(top_logits, top_indc, tokens=None, logits=None):\n",
    "\n",
    "    fontsize = 12\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 2), gridspec_kw={'hspace': 0.4})\n",
    "\n",
    "    x = np.arange(0,top_logits.shape[-1])\n",
    "    top1, = ax.plot(x, top_logits[...,0,:].detach().squeeze().numpy(), label=f\"top1 {model.to_string(top_indc[...,0,:])}\")\n",
    "    top2, = ax.plot(x, top_logits[...,1,:].detach().squeeze().numpy(), label=f\"top2 {model.to_string(top_indc[...,1,:])}\")\n",
    "\n",
    "    #fig.suptitle('first2sec logits', fontsize=fontsize)\n",
    "    if tokens is not None:\n",
    "        tok_labels = []\n",
    "        tok_list = tokens.squeeze().tolist()[1:]\n",
    "        for i, tok in enumerate(tok_list):\n",
    "            tok_labels.append(model.tokenizer.convert_ids_to_tokens(tok))\n",
    "        ax.set_xticks(x.tolist(), labels=tok_labels)\n",
    "\n",
    "    if logits is not None:\n",
    "        prefix_logits = logits[..., torch.arange(tokens.shape[-1]-1), tokens[0,1:]]\n",
    "        print(prefix_logits.shape, x, tokens.shape)\n",
    "        prompt_logs, = ax.plot(x, prefix_logits.detach().squeeze().numpy(), label=f\"prompt\", c=\"gray\", linestyle=\":\")\n",
    "\n",
    "    ax.set_xlabel('token pos', fontsize=fontsize)\n",
    "    ax.set_ylabel('log probs', fontsize=fontsize)\n",
    "    ax.legend(handles=[top1, top2], loc='upper left')\n",
    "    #ax.savefig(\"...\", dpi=200, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2aceba-7705-4176-8e81-0f9e14a0aad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_scores(prefix_score, prefix_str=None, topK_scores=None, topK_toks=None):\n",
    "\n",
    "    fontsize = 12\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 3), gridspec_kw={'hspace': 0.4})\n",
    "    legend_lines = []\n",
    "    \n",
    "    x = np.arange(0, prefix_score.shape[-1])\n",
    "    prompt_logs, = ax.plot(x, prefix_score.detach().squeeze().numpy(), label=f\"prefix\", c=\"gray\", linestyle=\":\")\n",
    "    legend_lines.append(prompt_logs)\n",
    "    \n",
    "    if prefix_str is not None:\n",
    "        prefix_str_list = model.to_str_tokens(prefix_str)[1:]\n",
    "        ax.set_xticks(x.tolist(), labels=prefix_str_list)\n",
    "\n",
    "    if topK_scores is not None and topK_toks is not None:\n",
    "        cmap = plt.cm.viridis\n",
    "        norm = mpl.colors.Normalize(0,topK_scores.shape[-1])\n",
    "        colors = cmap(norm(range(topK_scores.shape[-1])))\n",
    "        for seq_idx in range(topK_scores.shape[-1]):\n",
    "            topK_line, = ax.plot(x, topK_scores[...,:-1,seq_idx].detach().squeeze().numpy(), c=colors[seq_idx], label=f\"top{seq_idx+1}\")\n",
    "            legend_lines.append(topK_line)\n",
    "            topK_string = model.to_str_tokens(topK_toks[...,:,seq_idx])\n",
    "    \n",
    "            for tick_idx, tick in enumerate(ax.get_xticklabels()):\n",
    "                tick_pos = tick.get_position()\n",
    "                x_pos = -0.3 + tick_pos[0]\n",
    "                y_pos = -0.25 - (seq_idx/10)\n",
    "                ax.text(x_pos,y_pos,s=topK_string[tick_idx], c=colors[seq_idx]) # transform=ax.transAxes\n",
    "        \n",
    "    #ax.set_xlabel('token pos', fontsize=fontsize)\n",
    "    ax.set_ylabel('score', fontsize=fontsize)\n",
    "    ax.legend(handles=legend_lines, loc='upper left')\n",
    "    #ax.savefig(\"...\", dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29e965-d510-4810-af19-4fc22be93541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"An apple a day keeps the doctor away\"\n",
    "#prefix = \"In the town where I was born. Lived a man who sailed to sea. And he told us of his life. In the land of submarines\"\n",
    "#prefix = \"So we sailed on to the sun. Till we found the sea of green. And we lived beneath the waves. In our yellow submarine\"\n",
    "\n",
    "#prefix = \"Our Father in heaven, hallowed be your name, your kingdom come, your will be done, on earth as in heaven.\"\n",
    "\n",
    "toks_I = model.to_tokens(prefix)\n",
    "logits_NIT = model(toks_I)\n",
    "scores_NIT = (torch.nn.functional.softmax(logits_NIT, dim=-1))\n",
    "\n",
    "scores_I = helpers.gather_token_scores(scores_NIT, toks_I, pool=[])\n",
    "top_scores_Ik, top_idcs_Ik = helpers.get_topK(scores_NIT, topK=2, minK=False)\n",
    "print(top_scores_Ik.shape, len(model.to_str_tokens(prefix)))\n",
    "\n",
    "plot_scores(scores_I, prefix, top_scores_Ik, top_idcs_Ik)\n",
    "\n",
    "#top_logits, top_indc = torch.topk(logits[...,:-1,:], 20, dim=-1)\n",
    "#top_logits, top_indc = torch.transpose(top_logits,-2, -1), torch.transpose(top_indc,-2, -1)\n",
    "#print(model.to_string(top_indc[...,:,0]), top_logits[...,:,0].sum().item())\n",
    "#print(model.to_string(top_indc[...,:,1]), top_logits[...,:,1].sum().item())\n",
    "#plot_scores(top_logits, top_indc, tokens, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34168d30-87dc-4db7-abed-d0d96578dd56",
   "metadata": {
    "id": "34168d30-87dc-4db7-abed-d0d96578dd56",
    "outputId": "6224c7af-3b20-488d-fa3e-2869b655d5dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"Our Father in heaven, hallowed be your name, your kingdom come, your will be done, on earth as in heaven.\"\n",
    "prefix = \"Lead us not into temptation but deliver us from evil. For the kingdom, the power, and the glory are yours now and forever. Amen.\"\n",
    "\n",
    "prefix = \"Twinkle, twinkle, little star, How I wonder what you are! Up above the world so high, Like a diamond in the sky.\"\n",
    "prefix = \"When the blazing sun is gone, When he nothing shines upon, Then you show your little light, Twinkle, twinkle, all the night.\"\n",
    "\n",
    "toks_I = model.to_tokens(prefix)\n",
    "logits_NIT = model(toks_I)\n",
    "scores_NIT = (torch.nn.functional.softmax(logits_NIT, dim=-1))\n",
    "\n",
    "top_scores_Ik, top_idcs_Ik = helpers.get_topK(scores_NIT, topK=20, minK=False)\n",
    "scores_I = helpers.gather_token_scores(scores_NIT, toks_I, pool=[])\n",
    "(top_scores_Ik[...,:-1,0] - scores_I).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b97b47-88f7-4d26-acd2-65d5ccdb4488",
   "metadata": {
    "id": "e1b97b47-88f7-4d26-acd2-65d5ccdb4488",
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_I.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ac686-5ab4-4bc7-a8cf-d2115eda3e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

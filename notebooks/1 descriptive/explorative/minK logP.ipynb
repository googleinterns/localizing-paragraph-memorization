{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7cca97",
   "metadata": {},
   "source": [
    "\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed0ebd-d2aa-446b-b800-41032dcfddca",
   "metadata": {
    "id": "12ed0ebd-d2aa-446b-b800-41032dcfddca"
   },
   "source": [
    "# MinK LogProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136ac01-5b16-4d00-83d2-5a26ba06f96a",
   "metadata": {
    "id": "5136ac01-5b16-4d00-83d2-5a26ba06f96a"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "torch.set_grad_enabled(False)\n",
    "from functools import partial\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590e2de-65c7-4322-a834-24bd6ff7d5ee",
   "metadata": {
    "id": "f590e2de-65c7-4322-a834-24bd6ff7d5ee",
    "outputId": "05409e1e-7bde-4b7d-ab00-e3e4e5d0c186"
   },
   "outputs": [],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0325fd8-1a5e-4c6d-9b76-4553aef270e0",
   "metadata": {
    "id": "b0325fd8-1a5e-4c6d-9b76-4553aef270e0"
   },
   "outputs": [],
   "source": [
    "def prompt_likelihood(prompt, min_k =3):\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    logits, activs = model.run_with_cache(tokens)\n",
    "    logits = logits[...,:-1,:]\n",
    "    #print(f\"model likelihood: {logits.sum().item()}\")\n",
    "    log_probs = torch.log(torch.nn.functional.softmax(logits, dim=-1))\n",
    "    pred_toks = tokens.squeeze()[1:] ## shift pack tokens by one index\n",
    "    lik = log_probs[...,torch.arange(pred_toks.shape[-1]),pred_toks]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 2), gridspec_kw={'hspace': 0.4})\n",
    "    ax = sns.heatmap(lik, cmap=mpl.colormaps[\"Blues_r\"], xticklabels=model.tokenizer.convert_ids_to_tokens(pred_toks.squeeze()), square=False)\n",
    "    if isinstance(min_k, int):\n",
    "        lik, lik_indeces = torch.topk(lik, min_k, largest=False, sorted=True)\n",
    "        #print(model.tokenizer.convert_ids_to_tokens(pred_toks[lik_indeces].squeeze()))\n",
    "    log_lik = lik.mean()#torch.log(lik).mean()\n",
    "    print(f\"MIN-k={min_k} logprob: {log_lik}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1fc65-9487-4a52-908b-4fa76105a7f4",
   "metadata": {
    "id": "c5b1fc65-9487-4a52-908b-4fa76105a7f4",
    "outputId": "6414498e-7868-4092-a9e9-8b69f6fecc5b"
   },
   "outputs": [],
   "source": [
    "prompt = 'An apple a day keeps the doctor away\"'\n",
    "#prompt = \"The US anthem goes as follows: O! say can you see by the dawn's early light,\\nWhat so proudly we hailed by the twilight's last gleaming,\"\n",
    "prompt_likelihood(prompt)\n",
    "\n",
    "prompt = 'An doctor a day keeps the nurse away\"'\n",
    "#prompt = \"The US anthem goes as follows: O! say can you saw by the dawn's early morning,\\nWhat so proudly we hailed by the twilight's last gleaming,\"\n",
    "prompt_likelihood(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5add0-00da-4a5a-84c4-f556f0bc11c1",
   "metadata": {
    "id": "a5f5add0-00da-4a5a-84c4-f556f0bc11c1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "venv",
   "name": ".m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m114"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

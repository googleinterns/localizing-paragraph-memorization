{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3b1670",
   "metadata": {},
   "source": [
    "\n",
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bdcc2-c295-489c-b794-d77edaddbd09",
   "metadata": {},
   "source": [
    "# Token Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de6b74-d98d-4198-a1af-88651395b95c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import transformer_lens\n",
    "import torch, gc, itertools, functools, tqdm, copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jupyter/')\n",
    "from paraMem.utils import modelHandlers, dataLoaders, gradient, evaluation, localizing, intervening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62459d8-c4c9-4794-a9dd-914e6e3cfdb4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0aa36a-d073-4a33-b5cd-708e828fcae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = \"gpt-neo-125M\"\n",
    "model = modelHandlers.load_model(model_type=model_type, DEVICE=\"cpu\", lr=0.0, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12505d94-77a0-4d96-895f-568e291acc27",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f53327-ea8b-4c6d-a497-adc0161adba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mem_nonmem_sets  = dataLoaders.load_pile_splits(f\"{model_type}/preds\", file_names=[\"50_50_preds.pt\", \"0_10_preds.pt\"], as_torch=True)\n",
    "mem_set, non_mem_set = mem_nonmem_sets[0], mem_nonmem_sets[1]\n",
    "train_dl, test_dl = dataLoaders.train_test_batching(mem_set, non_mem_set, mem_batch=100, non_mem_batch=1, test_frac=0.2, add_bos=None, shuffle=False)\n",
    "c_toks_NI, k_toks_NI = next(iter(train_dl))\n",
    "c_toks_NI, k_toks_NI = c_toks_NI.squeeze(0), k_toks_NI.squeeze(0)\n",
    "\n",
    "\n",
    "#c_string_NI = [\"Sign up for Take Action Now and get three actions in your inbox every week. You will receive occasional promotional offers for programs that support The Nationâ€™s journalism. You can read our Privacy Policy here. Sign up for Take Action Now and get three actions in your inbox every week.\\n\\nThank you for signing up. For more from The Nation, check out our latest issue\\n\\nSubscribe now for as little as $2 a month!\\n\\nSupport Progressive Journalism The Nation is reader supported:\"]\n",
    "c_string_NI = [\"The following are trademarks or service marks of Major League Baseball entities and may be used only with permission of Major League Baseball Properties, Inc. or the relevant Major League Baseball entity: Major League, Major League Baseball, MLB, the silhouetted batter logo, World Series, National League, American League, Division Series, League Championship Series, All-Star Game, and the names, nicknames, logos, uniform designs, color combinations, and slogans designating the Major League Baseball clubs and entities, and\"]\n",
    "#c_string_NI = [\" headlines out of Washington never seem to slow. Subscribe to The D.C. Brief to make sense of what matters most. Please enter a valid email address. Sign Up Now Check the box if you do not wish to receive promotional offers via email from TIME. You can unsubscribe at any time. By signing up you are agreeing to our Terms of Use and Privacy Policy . This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Thank you! For your\"]\n",
    "c_toks_NI = model.to_tokens(c_string_NI, prepend_bos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db5db5-5e08-4847-8aac-1d3adf37fda4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for i in range(0,100):\n",
    "#    print(i, model.to_string(c_toks_NI[i]))\n",
    "#model.to_string(c_toks_NI[6])\n",
    "#c_toks_NI = c_toks_NI[6].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f999479-8cf6-43f7-9e70-8aeceafd3788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompt = \"Our Father, who art in heaven, hallowed be thy name; thy kingdom come; thy will be done; on earth as it is in heaven. Give us this day our daily bread. And forgive us our trespasses, as we forgive those who trespass against us. And lead us not into temptation; but deliver us from evil\"\n",
    "#prompt = \"An apple a day keeps the doctor away\"\n",
    "#tokens_NI = model.to_tokens(prompt, prepend_bos=True)\n",
    "toks_NI = c_toks_NI\n",
    "print(model.to_string(toks_NI))\n",
    "pref_cont_split = 50#int(tokens_NI.shape[-1] / 2)\n",
    "pref_NI = toks_NI[:,:pref_cont_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9e84f-50f7-42f4-b642-fb8c036eedf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_first2sec_tok(logits_NIT:torch.Tensor, prefix_NI:torch.Tensor, keepNonTop:bool=True):\n",
    "    \"\"\"\n",
    "    pertubate sequence via first and second most likely tokens\n",
    "    \"\"\"\n",
    "    scores_NIT = (torch.nn.functional.softmax(logits_NIT.to(\"cpu\"), dim=-1))\n",
    "    prefix_scores_NI = modelHandlers.gather_token_scores(scores_NIT, prefix_NI)\n",
    "    top_scores_Ik, top_idcs_Ik = modelHandlers.get_topK(scores_NIT, topK=2, minK=False)\n",
    "    \n",
    "    pertubed_prefix = torch.clone(prefix_NI[:,1:]).long()\n",
    "    prefixIsTop = torch.where(top_idcs_Ik[...,:-1,0] == prefix_NI[:,1:], 1, 0)\n",
    "    pertubed_prefix[prefixIsTop.bool()] = top_idcs_Ik[...,:-1,1][prefixIsTop.bool()] ## pick top 2\n",
    "    if keepNonTop:\n",
    "        pertubed_prefix[~prefixIsTop.bool()] = top_idcs_Ik[...,:-1,0][~prefixIsTop.bool()] ## pick top 1\n",
    "    \n",
    "    ## add BOS token\n",
    "    bos_N = prefix_NI[:,0].unsqueeze(-1)\n",
    "    pertubed_prefix = torch.cat((bos_N, pertubed_prefix), dim=-1)\n",
    "    return pertubed_prefix\n",
    "    \n",
    "def get_random_tok(prefix_NI:torch.Tensor, vocab_size:int=50257, seed:int=0): \n",
    "    \"\"\"\n",
    "    pertubate sequence via random tokens (vocab_size = model.cfg.d_vocab)\n",
    "    \"\"\"\n",
    "    if seed >= 0:\n",
    "        print(f\"fixed torch seed {seed}\")\n",
    "        torch.manual_seed(seed)\n",
    "    pertubed_prefix = torch.randint(0, vocab_size, prefix_NI.shape)[...,:-1]\n",
    "    \n",
    "    ## add BOS token\n",
    "    bos_N = prefix_NI[:,0].unsqueeze(-1)\n",
    "    pertubed_prefix = torch.cat((bos_N, pertubed_prefix), dim=-1)\n",
    "    return pertubed_prefix\n",
    "\n",
    "perturb_type = \"random\" #first2sec\n",
    "\n",
    "if perturb_type==\"first2sec\":\n",
    "    pertubed_prefix_NI = get_first2sec_tok(model(pref_NI[:,:pref_cont_split]).to(\"cpu\"), pref_NI, keepNonTop=True)\n",
    "    print(model.to_string(pertubed_prefix_NI), pertubed_prefix_NI.shape)\n",
    "\n",
    "elif perturb_type==\"random\":\n",
    "    pertubed_pref_NI = get_random_tok(pref_NI, vocab_size= model.cfg.d_vocab, seed=-1)\n",
    "    print(model.to_string(pertubed_pref_NI), pertubed_pref_NI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e5dd28-4203-42f9-b719-2cf43033f060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def token_patching_loop(model, toks_NI=torch.tensor, pertubed_pref_NI=torch.tensor, decode:bool=False, single_tok_perturb:bool=True, disable_tqdm:bool=False):\n",
    "    \"\"\"\n",
    "    loop over all tokens in the prefix, pertubate them and measure the change in the continuation\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        pref_NI, cont_NI, n_toks = toks_NI[:,:pertubed_pref_NI.shape[-1]], toks_NI[:,-pertubed_pref_NI.shape[-1]:], pertubed_pref_NI.shape[-1]\n",
    "\n",
    "        nll_metric, em_metric = torch.zeros(pref_NI.shape[0], pref_NI.shape[-1]), torch.zeros(pref_NI.shape[0], pref_NI.shape[-1])\n",
    "        toks_NI = torch.cat((pref_NI, cont_NI), dim=-1)\n",
    "        orig_toks_nll = modelHandlers.gather_token_scores(modelHandlers.NegLogLik(model(toks_NI.to(model.cfg.device)).to(\"cpu\")), toks_NI)\n",
    "\n",
    "        interv_tok_pos, min_em, most_changed_preds = torch.zeros(cont_NI.shape[0]).long(), torch.ones(cont_NI.shape[0])*9999, torch.zeros(cont_NI.shape).long()\n",
    "        for tok_pos in tqdm.tqdm(range(n_toks), total=n_toks, disable=disable_tqdm):\n",
    "\n",
    "            ## (1) intervene on token at token position\n",
    "            pref_NI_interv = torch.clone(pref_NI)\n",
    "            if single_tok_perturb:\n",
    "                pref_NI_interv[:,tok_pos] = pertubed_pref_NI[:,tok_pos]\n",
    "            else:\n",
    "                pref_NI_interv[:,:tok_pos] = pertubed_pref_NI[:,:tok_pos]\n",
    "\n",
    "            ## (2) generate continuation on intervened token sequence\n",
    "            if decode: #[:,:prefix_NI.shape[-1]]\n",
    "                pred_toks_NI = model.generate(input=pref_NI_interv, use_past_kv_cache=True, stop_at_eos=False, max_new_tokens=cont_NI.shape[-1], do_sample=False)\n",
    "                pred_nll_NIT = modelHandlers.NegLogLik(model(pred_toks_NI).detach().to(\"cpu\"))\n",
    "                pred_nll_NI = modelHandlers.gather_token_scores(pred_nll_NIT, pred_toks_NI.to(\"cpu\"))\n",
    "\n",
    "                pred_toks_NI = pred_toks_NI[:,-cont_NI.shape[-1]:].to(\"cpu\")\n",
    "                cont_NI_test = torch.clone(cont_NI).to(\"cpu\")\n",
    "\n",
    "\n",
    "            else: ## argmax decoding\n",
    "                toks_NI_interv = torch.cat((pref_NI_interv, cont_NI), dim=-1)\n",
    "                pred_nll_NIT = modelHandlers.NegLogLik(model(toks_NI_interv.to(model.cfg.device)).to(\"cpu\"))\n",
    "\n",
    "                pred_nll_NI = modelHandlers.gather_token_scores(pred_nll_NIT, toks_NI) ## get pred NLL \n",
    "                _, pred_toks_NIk = modelHandlers.get_topK(pred_nll_NIT, topK=1, minK=True) ## get argmax toks \n",
    "                pred_toks_NI = pred_toks_NIk[...,-(cont_NI.shape[-1]+1):-1,0].to(\"cpu\")\n",
    "                cont_NI_test = torch.clone(cont_NI[...,:]).to(\"cpu\")\n",
    "\n",
    "            ## (3) evaluate the generated continuation against the original continuation\n",
    "            nll_metric[:,tok_pos] = pred_nll_NI[:,-cont_NI.shape[-1]:].mean(-1)   \n",
    "\n",
    "            em = evaluation.compute_exact_match(pred_toks_NI, cont_NI_test, until_wrong=True)\n",
    "            em_metric[:,tok_pos] = em\n",
    "\n",
    "            ## (4) update minimum em and most_changed_preds\n",
    "            select_mask = torch.where(em < min_em, 1, 0)\n",
    "            select_idcs = torch.nonzero(select_mask.bool()).squeeze()\n",
    "            interv_tok_pos[select_idcs] = tok_pos\n",
    "            min_em[select_idcs] = em[select_idcs]\n",
    "            most_changed_preds[select_idcs,:] = pred_toks_NI[select_idcs,:].detach()        \n",
    "    return nll_metric, em_metric, most_changed_preds, interv_tok_pos\n",
    "\n",
    "nll_metric, em_metric, most_changed_preds, min_tok_pos = token_patching_loop(model, toks_NI, pertubed_pref_NI, single_tok_perturb=True, decode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6df94-e978-412e-9ac5-072da9d8085b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to_string(toks_NI[:,:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c6181-5c76-4729-96b7-e86f53cf1caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to_string(toks_NI[:,50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8785a9-2ecc-4d38-83c4-fff371bcda14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to_string(most_changed_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac652a-c76f-4d66-b53c-26f22a1be429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nll_baseline = nll_metric[...,0,0].mean().item()\n",
    "em_baseline = em_metric[...,0,0].mean().item()\n",
    "\n",
    "nll = nll_metric[...,0,:].numpy()\n",
    "em = em_metric[...,0,:].numpy()\n",
    "\n",
    "x = np.arange(0,em.shape[-1])\n",
    "true_prefix=model.to_str_tokens(pref_NI.squeeze())\n",
    "pertubed_prefix=model.to_str_tokens(pertubed_pref_NI.squeeze())\n",
    "\n",
    "xlabels = true_prefix\n",
    "#xlabels = [a + r\" $\\rightarrow$ \" + b for (a,b) in zip(true_prefix, pertubed_prefix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a8824-8427-4f6b-b5cb-ffd5eb5754e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(15, 2), gridspec_kw={'hspace': 0.4})\n",
    "fontsize = 12\n",
    "\n",
    "ax[0].axhline(y=nll_baseline, linewidth=1, linestyle='--', c=\"grey\", alpha=0.5)\n",
    "ax[0].plot(x, nll, c=\"black\")\n",
    "ax[0].set_ylabel(r'NLL', fontsize=fontsize) #\\searrow\n",
    "ax[0].set_xticks([])\n",
    "#ax[0].yscale(\"log\")\n",
    "ax[0].axvline(x=min_tok_pos, c=\"orange\", linestyle='-')\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "\n",
    "ax[1].axhline(y=em_baseline, linewidth=1, linestyle='--', c=\"grey\", alpha=0.5)\n",
    "ax[1].plot(x, em, c=\"black\")\n",
    "ax[1].set_ylabel(r'EM', fontsize=fontsize) #\\searrow\n",
    "ax[1].axvline(x=min_tok_pos, c=\"orange\", linestyle='-')\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "\n",
    "ax[1].set_xticks(x)\n",
    "labels = ax[1].set_xticklabels(xlabels, fontsize=fontsize-2, rotation=90)\n",
    "\n",
    "#fig.savefig(f\"{dataLoaders.ROOT}/results/{model_type}_{perturb_type}_perturb.pdf\", dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac07bb1-ac03-453c-8c28-9464d15f02f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#nll_NI = modelHandlers.gather_tokenr_scores(model(tokens_NI), tokens_NI) ## get pred NLL \n",
    "logs = model(c_toks_NI)\n",
    "_, pred_k = modelHandlers.get_topK(logs, topK=1, minK=False) ## get argmax toks \n",
    "model.to_string(pred_k[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f992a88-5d1a-40af-9a2b-a294056aaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_toks_NI = model.generate(input=pref_NI, use_past_kv_cache=True, stop_at_eos=False, max_new_tokens=50, do_sample=False)\n",
    "model.to_string(pred_toks_NI[...,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3650c70-1528-4462-af39-a866861366f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_toks_NI\n",
    "evaluation.compute_exact_match(pred_toks_NI[:,50:], c_toks_NI[:,50:], until_wrong=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c8443-5342-4b2b-9768-59b4c2fe8fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to_string(c_toks_NI[...,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91517a-cbcd-4c52-b6d8-34d770b02e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-venv",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "venv (Local)",
   "language": "python",
   "name": "conda-root-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
